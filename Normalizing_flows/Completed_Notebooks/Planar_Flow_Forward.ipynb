{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.distributions import MultivariateNormal\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "D53jAQq6R5bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PlanarFlow (from your code) ===\n",
        "class PlanarFlow(nn.Module):\n",
        "    def __init__(self, dim, h=torch.tanh, hp=lambda x: 1 - torch.tanh(x) ** 2):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(1, dim) * 0.01)\n",
        "        self.scale = nn.Parameter(torch.randn(1, dim) * 0.01)\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "        self.h = h\n",
        "        self.hp = hp\n",
        "\n",
        "    def forward(self, z):\n",
        "        f_z = F.linear(z, self.weight, self.bias)\n",
        "        return z + self.scale * self.h(f_z)\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        f_z = F.linear(z, self.weight, self.bias)\n",
        "        psi = self.hp(f_z) * self.weight  # (B, D)\n",
        "        det_grad = 1 + torch.mm(psi, self.scale.t())\n",
        "        return torch.log(det_grad.abs() + 1e-9).squeeze()\n",
        "\n",
        "\n",
        "# === Normalizing Flow Model ===\n",
        "class NormalizingFlowModel(nn.Module):\n",
        "    def __init__(self, flows, base_dist):\n",
        "        super().__init__()\n",
        "        self.flows = nn.ModuleList(flows)\n",
        "        self.base_dist = base_dist\n",
        "\n",
        "    def forward(self, x):\n",
        "        log_det = 0\n",
        "        for flow in self.flows:\n",
        "            log_det = log_det + flow.log_abs_det_jacobian(x)\n",
        "            x = flow(x)\n",
        "        return x, log_det\n",
        "\n",
        "    def inverse(self, z):\n",
        "        # Needed for sampling from base to data space\n",
        "        for flow in reversed(self.flows):\n",
        "            # No analytical inverse – Planar flow not invertible algebraically\n",
        "            raise NotImplementedError(\"Planar flow inverse is not defined.\")\n",
        "        return z"
      ],
      "metadata": {
        "id": "hY6wuoEmOa1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "MeOfF3-YO0eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"/content/blobs.json\"\n",
        "with open(filename, 'r') as file:\n",
        "    data = json.load(file)\n",
        "Data=torch.tensor(data['X'])\n",
        "\n",
        "# Compute the mean\n",
        "mean_x = Data.mean(axis=0)\n",
        "\n",
        "# Center the data\n",
        "X_centered = Data - mean_x"
      ],
      "metadata": {
        "id": "lrWO_foKRDQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = torch.tensor(X_centered, dtype=torch.float32).to(device)"
      ],
      "metadata": {
        "id": "AfebdqEfRMWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to NumPy\n",
        "data = X_centered.numpy()\n",
        "\n",
        "# Extract x and y\n",
        "x = data[:, 0]\n",
        "y = data[:, 1]\n",
        "\n",
        "# Plot 2D histogram\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.hist2d(x, y, bins=100, cmap='plasma')  # You can adjust 'bins' and 'cmap'\n",
        "plt.colorbar(label='Counts')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('Y')\n",
        "plt.title('2D Histogram of Target Distribution')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7XQJRnHvVLSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = x_data.shape[1]\n",
        "base_dist = MultivariateNormal(loc=torch.zeros(dim).to(device),\n",
        "                               covariance_matrix=torch.eye(dim).to(device))"
      ],
      "metadata": {
        "id": "ecAe6crXRTqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flows = [PlanarFlow(dim).to(device) for _ in range(8)]\n",
        "model = NormalizingFlowModel(flows, base_dist).to(device)"
      ],
      "metadata": {
        "id": "qF0k4nCvRYmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "num_epochs = 5000\n",
        "batch_size = 256\n",
        "\n",
        "losses = []\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    idx = torch.randint(0, x_data.shape[0], (batch_size,))\n",
        "    x_batch = x_data[idx]\n",
        "\n",
        "    z, log_det = model(x_batch)\n",
        "    log_prob = model.base_dist.log_prob(z)\n",
        "    loss = -(log_prob + log_det).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"[{epoch}] Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "K4CI0bRMRcS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    z_latent, _ = model(x_data)\n",
        "\n",
        "    # Optionally check if z_latent ∼ N(0, I)\n",
        "    z_np = z_latent.cpu().numpy()\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    if dim == 2:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.hist2d(z_np[:, 0], z_np[:, 1], bins=100, density=True, cmap=\"viridis\")\n",
        "        plt.title(\"Transformed z (should look like N(0,I))\")\n",
        "        plt.colorbar()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "1WWC4QavRhh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzXCzUi1RuRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now do this with Normflows package"
      ],
      "metadata": {
        "id": "w-clItfvSROx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import normflows as nf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "03PVpwwWSTtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_flows = 8\n",
        "# --- Define base distribution (Standard Normal) ---\n",
        "q0 = nf.distributions.base.DiagGaussian(dim)\n",
        "\n",
        "# --- Create list of Planar flows ---\n",
        "flows = [nf.flows.Planar(dim) for _ in range(num_flows)]\n",
        "\n",
        "# --- Create the flow model ---\n",
        "model = nf.NormalizingFlow(q0=q0, flows=flows)"
      ],
      "metadata": {
        "id": "hfQKUl2TSUo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Training parameters ===\n",
        "num_iter = 5000\n",
        "batch_size = 256\n",
        "lr = 1e-3\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# --- Training loop ---\n",
        "losses = []\n",
        "for it in tqdm(range(num_iter)):\n",
        "    idx = torch.randint(0, x_data.shape[0], (batch_size,))\n",
        "    x = x_data[idx]\n",
        "\n",
        "    # log_prob handles forward pass and log_det\n",
        "    z = x\n",
        "    log_det = 0.\n",
        "    for flow in model.flows:\n",
        "        z, ld = flow(z)\n",
        "        log_det += ld\n",
        "\n",
        "    log_q0 = model.q0.log_prob(z)\n",
        "    loss = -(log_q0 + log_det).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if it % 500 == 0:\n",
        "        print(f\"[{it}] Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "LNY-ZGYQSaUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    z = x_data.clone()\n",
        "    for flow in model.flows:\n",
        "        z, _ = flow(z)  # Only forward transform, discard log_det"
      ],
      "metadata": {
        "id": "AkwkqIPFVpPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Original data\n",
        "axs[0].scatter(x_data[:, 0], x_data[:, 1], s=5, alpha=0.6)\n",
        "axs[0].set_title(\"Original data\")\n",
        "\n",
        "# Transformed to latent space\n",
        "axs[1].scatter(z[:, 0], z[:, 1], s=5, alpha=0.6)\n",
        "axs[1].set_title(\"Transformed to latent space\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7oDKKlOVVsDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "dim = 2  # Dimensionality of the data\n",
        "num_flows = 8\n",
        "num_iter = 5000\n",
        "batch_size = 256\n",
        "\n",
        "# --- Define base distribution (Standard Normal) ---\n",
        "q0 = nf.distributions.base.DiagGaussian(dim)\n",
        "\n",
        "# --- Create list of Planar flows ---\n",
        "flows = [nf.flows.Planar(dim) for _ in range(num_flows)]\n",
        "\n",
        "# --- Create the flow model ---\n",
        "model = nf.NormalizingFlow(q0=q0, flows=flows)\n",
        "\n",
        "# --- Optimizer ---\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# --- Create some new dummy data\n",
        "x_data = torch.tensor(\n",
        "    np.concatenate([\n",
        "        np.random.randn(1000, 2) * 0.5 + np.array([2, 2]),\n",
        "        np.random.randn(1000, 2) * 0.5 + np.array([-2, -2])\n",
        "    ], axis=0),\n",
        "    dtype=torch.float32\n",
        ")"
      ],
      "metadata": {
        "id": "ndNIcAjbSfaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training loop ---\n",
        "losses = []\n",
        "for it in tqdm(range(num_iter)):\n",
        "    idx = torch.randint(0, x_data.shape[0], (batch_size,))\n",
        "    x = x_data[idx]\n",
        "\n",
        "    # log_prob handles forward pass and log_det\n",
        "    z = x\n",
        "    log_det = 0.\n",
        "    for flow in model.flows:\n",
        "        z, ld = flow(z)\n",
        "        log_det += ld\n",
        "\n",
        "    log_q0 = model.q0.log_prob(z)\n",
        "    loss = -(log_q0 + log_det).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if it % 500 == 0:\n",
        "        print(f\"[{it}] Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "7AMtWAHnTTi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    z = x_data.clone()\n",
        "    for flow in model.flows:\n",
        "        z, _ = flow(z)  # Only forward transform, discard log_det"
      ],
      "metadata": {
        "id": "VQr1Il_kUAxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Original data\n",
        "axs[0].scatter(x_data[:, 0], x_data[:, 1], s=5, alpha=0.6)\n",
        "axs[0].set_title(\"Original data\")\n",
        "\n",
        "# Transformed to latent space\n",
        "axs[1].scatter(z[:, 0], z[:, 1], s=5, alpha=0.6)\n",
        "axs[1].set_title(\"Transformed to latent space\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9iKv1JF0UbNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YY3n0Z5FUsTZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}