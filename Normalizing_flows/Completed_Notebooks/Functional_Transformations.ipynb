{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b3c6378-4702-4160-859c-4ff81029b2d7",
      "metadata": {
        "id": "5b3c6378-4702-4160-859c-4ff81029b2d7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as distrib\n",
        "import torch.distributions.transforms as transform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A demonstration of functions and transformations in pyTorch Module"
      ],
      "metadata": {
        "id": "mbMs158jg_pR"
      },
      "id": "mbMs158jg_pR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c39ec83-d4a0-4035-a6c5-b4cbc55ed882",
      "metadata": {
        "id": "7c39ec83-d4a0-4035-a6c5-b4cbc55ed882"
      },
      "outputs": [],
      "source": [
        "# Define grid for 2D plotting\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
        "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])\n",
        "z_torch = torch.tensor(z, dtype=torch.float32)\n",
        "\n",
        "# Univariate Normal\n",
        "n = distrib.Normal(0, 1)\n",
        "samples = n.sample((1000,))\n",
        "density = torch.exp(n.log_prob(torch.tensor(x, dtype=torch.float32))).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82835408-8cf6-43f2-9799-7e6756f3a671",
      "metadata": {
        "id": "82835408-8cf6-43f2-9799-7e6756f3a671"
      },
      "outputs": [],
      "source": [
        "radialfig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize=(15, 4))\n",
        "ax1.hist(samples.numpy(), bins=50, alpha=0.8)\n",
        "ax1.set_title('Empirical samples', fontsize=18)\n",
        "ax2.plot(x, density)\n",
        "ax2.fill_between(x, density, 0, alpha=0.5)\n",
        "ax2.set_title('True density', fontsize=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6793c16d-69a0-4952-a533-342cfd23532f",
      "metadata": {
        "id": "6793c16d-69a0-4952-a533-342cfd23532f"
      },
      "outputs": [],
      "source": [
        "# Transformed distribution: q1 = exp(N(0,1))\n",
        "q0 = distrib.Normal(0, 1)\n",
        "exp_t = transform.ExpTransform()\n",
        "q1 = distrib.TransformedDistribution(q0, [exp_t])\n",
        "\n",
        "samples_q0 = q0.sample((int(1e4),))\n",
        "samples_q1 = q1.sample((int(1e4),))\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 4))\n",
        "ax1.hist(samples_q0.numpy(), bins=50, alpha=0.8)\n",
        "ax1.set_title('$q_0 = \\mathcal{N}(0,1)$', fontsize=18)\n",
        "ax2.hist(samples_q1.numpy(), bins=50, alpha=0.8, color='g')\n",
        "ax2.set_title('$q_1=\\\\exp(q_0)$', fontsize=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b793dda3-05ce-4d22-817b-f6139da3b34d",
      "metadata": {
        "id": "b793dda3-05ce-4d22-817b-f6139da3b34d"
      },
      "outputs": [],
      "source": [
        "# Plot density of q0 and q1\n",
        "x_pos = np.linspace(0.001, 10, 1000)\n",
        "q0_density = torch.exp(q0.log_prob(torch.tensor(x, dtype=torch.float32))).numpy()\n",
        "q1_density = torch.exp(q1.log_prob(torch.tensor(x_pos, dtype=torch.float32))).numpy()\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=False, figsize=(15, 5))\n",
        "ax1.plot(x, q0_density)\n",
        "ax1.fill_between(x, q0_density, 0, alpha=0.5)\n",
        "ax1.set_title('$q_0 = \\mathcal{N}(0,1)$', fontsize=18)\n",
        "\n",
        "ax2.plot(x_pos, q1_density, color='g')\n",
        "ax2.fill_between(x_pos, q1_density, 0, alpha=0.5, color='g')\n",
        "ax2.set_title('$q_1=\\\\exp(q_0)$', fontsize=18)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving on to 2D Transformations"
      ],
      "metadata": {
        "id": "c1FvYL9lhdkq"
      },
      "id": "c1FvYL9lhdkq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155cbef1-9bae-4ea7-8639-ae6c1128cfdc",
      "metadata": {
        "id": "155cbef1-9bae-4ea7-8639-ae6c1128cfdc"
      },
      "outputs": [],
      "source": [
        "from torch.distributions import MultivariateNormal, TransformedDistribution, transforms as T\n",
        "\n",
        "# Base distribution\n",
        "q0 = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "\n",
        "# Transforms\n",
        "f1 = T.ExpTransform()\n",
        "q1 = TransformedDistribution(q0, f1)\n",
        "\n",
        "#f2 = T.AffineTransform(loc=torch.tensor([0.2, 2.0]), scale=torch.tensor([2.0, 2.0]))\n",
        "f2 = T.AffineTransform(2, torch.Tensor([0.2, 1.5]))\n",
        "q2 = TransformedDistribution(q0, [f1, f2])\n",
        "\n",
        "# Plot samples as 2D histograms (density estimate)\n",
        "def plot_samples(dist, title, bins=150, range=None):\n",
        "    samples = dist.sample((1000000,)).numpy()\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.hist2d(samples[:, 0], samples[:, 1], bins=bins, density=True, cmap=\"rainbow\", range=range)\n",
        "    plt.colorbar(label='Density')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot all three\n",
        "plot_samples(q0, \"Density of q0 =Multivariate Normal\", range=[[-5, 5], [-5, 5]])\n",
        "plot_samples(q1, \"Density of q1 = ExpTransform(q0)\", range=[[0, 4], [0, 5]])\n",
        "plot_samples(q2, \"Density of q2 = Affine(Exp(q0))\", range=[[0, 4], [0, 5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39138635-173d-4061-9f40-30922a14e5ce",
      "metadata": {
        "id": "39138635-173d-4061-9f40-30922a14e5ce"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Base distribution\n",
        "q0 = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "f1 = T.ExpTransform()\n",
        "q1 = TransformedDistribution(q0, f1)\n",
        "#f2 = T.AffineTransform(loc=torch.tensor([0.2, 1.5]), scale=torch.tensor([2.0, 2.0]))\n",
        "f2 = T.AffineTransform(2, torch.Tensor([0.2, 1.5]))\n",
        "q2 = TransformedDistribution(q0, [f1, f2])\n",
        "\n",
        "# KDE plotter\n",
        "def plot_kde(dist, title, clip=None):\n",
        "    samples = dist.sample((10000,)).numpy()\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.kdeplot(\n",
        "        x=samples[:, 0],\n",
        "        y=samples[:, 1],\n",
        "        fill=True,\n",
        "        cmap=\"rainbow\",\n",
        "        levels=100,\n",
        "        thresh=1e-5,\n",
        "        clip=clip,\n",
        "        bw_adjust=1.5\n",
        "    )\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot all 3\n",
        "plot_kde(q0, \"KDE of q0 = MultivariateNormal\", clip=[(-2.5, 2.5), (-2.5, 2.53)])\n",
        "plot_kde(q1, \"KDE of q1 = ExpTransform(q0)\", clip=[(0, 6), (0, 6)])\n",
        "plot_kde(q2, \"KDE of q2 = Affine(Exp(q0))\", clip=[(0, 4), (0, 4)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Begin with Flows. Restart the Kernal Before we proceed."
      ],
      "metadata": {
        "id": "qvrxDw7hhvJo"
      },
      "id": "qvrxDw7hhvJo"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.distributions import MultivariateNormal, TransformedDistribution, constraints, Transform\n",
        "import torch.nn as nn\n",
        "import torch.distributions as distrib\n",
        "import torch.distributions.transforms as transform\n",
        "# Imports for plotting\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "BNMcRH8ao6oA"
      },
      "id": "BNMcRH8ao6oA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Planar Flow Transform\n",
        "class PlanarFlow(Transform):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "\n",
        "    def __init__(self, weight, scale, bias):\n",
        "        super().__init__()\n",
        "        self.weight = weight  # shape: (1, D)\n",
        "        self.scale = scale    # shape: (1, D)\n",
        "        self.bias = bias      # shape: (1,) or scalar\n",
        "\n",
        "    def _call(self, z):\n",
        "        f_z = F.linear(z, self.weight, self.bias)\n",
        "        return z + self.scale * torch.tanh(f_z)\n",
        "\n",
        "    def log_abs_det_jacobian(self, z, y=None):\n",
        "        f_z = F.linear(z, self.weight, self.bias)\n",
        "        tanh_prime = 1 - torch.tanh(f_z) ** 2\n",
        "        psi = tanh_prime * self.weight\n",
        "        dot = torch.einsum('nd,nd->n', psi, self.scale)\n",
        "        return torch.log(torch.abs(1 + dot) + 1e-7)"
      ],
      "metadata": {
        "id": "nM_HN9YkpaRM"
      },
      "id": "nM_HN9YkpaRM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define weights\n",
        "w = torch.tensor([[4., 0.]])\n",
        "u = torch.tensor([[7., 0.]])\n",
        "b = torch.tensor([1.5])\n",
        "\n",
        "# Base and transformed distributions\n",
        "q0 = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "flow = PlanarFlow(weight=w, scale=u, bias=b)\n",
        "q1 = TransformedDistribution(q0, flow)\n",
        "\n",
        "# Sample\n",
        "z = q0.sample((100000,))        # from base\n",
        "q1_samples = q1.sample((100000,))  # from flow-transformed"
      ],
      "metadata": {
        "id": "iHILdxV-peX1"
      },
      "id": "iHILdxV-peX1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# q0 plot\n",
        "ax1.hexbin(z[:, 0], z[:, 1], C=torch.exp(q0.log_prob(z)), gridsize=80, cmap='rainbow')\n",
        "ax1.set_title(r'$q_0 = \\mathcal{N}(\\mathbf{0}, \\mathbb{I})$', fontsize=16)\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "\n",
        "# q1 plot\n",
        "ax2.hexbin(q1_samples[:, 0], q1_samples[:, 1], gridsize=80, cmap='rainbow')\n",
        "ax2.set_title(r'$q_1 = \\mathrm{planar}(q_0)$', fontsize=16)\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "APBUUD2xpkfv"
      },
      "id": "APBUUD2xpkfv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Flow class is:\n",
        "\n",
        "\n",
        "*   a PyTorch module with invertible transformation behavior (for use in normalizing flows),\n",
        "*   initialized with small random weights,\n",
        "*   made hashable so it can be used in sets or as keys in dictionaries."
      ],
      "metadata": {
        "id": "2_EFikkalnNe"
      },
      "id": "2_EFikkalnNe"
    },
    {
      "cell_type": "code",
      "source": [
        "class Flow(transform.Transform, nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        transform.Transform.__init__(self)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "    # Init all parameters\n",
        "    def init_parameters(self):\n",
        "        for param in self.parameters():\n",
        "            param.data.uniform_(-0.01, 0.01)\n",
        "\n",
        "    # Hacky hash bypass\n",
        "    def __hash__(self):\n",
        "        return nn.Module.__hash__(self)"
      ],
      "metadata": {
        "id": "eR_H7Ax3losE"
      },
      "id": "eR_H7Ax3losE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we implemented the planar flow proposed in the original paper by Rezende [1], which is defined as a function of the form:\n",
        "\n",
        "![Screenshot from 2025-07-04 00-11-10.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAW4AAAAsCAYAAABFRVJcAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAAtdEVYdENyZWF0aW9uIFRpbWUARnJpZGF5IDA0IEp1bHkgMjAyNSAxMjoxMToxMCBBTTh1V38AAAv2SURBVHic7dxhbBvnfcfxb0djZzjFES52hIKKSGax9uxL05iuG1AwFhrZQqWrpTjxmHiK3EKVurh2EidCl1RJI7hJGWWd6qC1WyQWjCxskVTzFlhBE8lDKgU1xG6O6Mz2KU1y7GBTaAwSs8DDKugZRHAvJMWUJdmiJdk84/8B9IY8Pfccn+d+99zD5/iZQqFQQAghhGv8ybWugBBCiNJIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcAshhMtIcLvdqEXXczG6U2pemzun4rT9sJf0/DYXF1FneontjWM5CyjESXJgxxbq/yFGx3N72HLbWu5obCP2wxh7onex83B60eq7WKTflBcJbjfLOyReOoj1pQZqq7R5/Yv+xShR39vEDiVx8ktcv+uNYxH/cR/+7VFM/cqLUWcsxmr3cegfW9m9fQPGSpPah1tp/U4rT/19lOoq7+LVeZFIvykvEtwu5iQOcvCjW4je6S/hvzTMr96P/9h+4icXMmy8joymsd5LkBxKM/eAUmG9vp+Bijrq5nmRnKuczP94qd7kRwOcoUFSN5hU3zxZpjeAWbmAq8KSkX5TTiS4XUCluom17KSx7i62PddPNg+oND1vJPFtqcNcUWKBRpDoXdD3b8mJssqdY9F9OLE0dR1JcqDl2zRG66lv7597KiCboOtdqLk3iO5ZyA41/OFaQhUa4GBbKbQ1GwhMZrXx5TBBYyHlF8k7JN/onv+0TjZBrP52Vq1axdod8Zmfhdv6zXVMgrvcqTRH9nWQ8ATQR9NkRybOQjWcoM82qL71Ss5yDX9wA9rJHqzzi1vdJaEcPv5dmrHxJSh7ZZBdsRZqqnQC6038cwyms8d7SGobCFYuZLR9EZXB/khReeu6BV4M5twB2Q9PMzw6z82NEK0vvkD0Jh1zYxDfjEN1Wb+5jklwl7vsCfpOQlV4By/++we821GL4YHMyQFSn/0CVZ+7smK1ChN/3mbAltteJzVIMusluD7ArLGcd7ASFqwyZwmzBcgOMfgHHdP0zb7fBRsr+T+c4UEsx4e53j9rnaTflAcJ7jKXtQcZUpXccnPxvKfD8Icp+DP/9CAZtThw3ypWrZr5t3ZHHLv41vcGA783i30md4l53YVTZ7povG32Om3Zl5znvkuo4UiCtr+e2sdtNL6eRuWzdD96+6f7vb2lt+hWX5E5mSS9Yh0bAnPMLas01u8dDL9xIczyWfpb75h+PK0x6ouOdW19J/a5JB1fm3rtDp7svxB4jj3IUL6SW2ab0y6lLS+htLZVZE4kSevrqJ7rs7hK/UZcmgR3mVJnumlr3EZ9S5x01qLru/XUP9pJ0gHyiuwnDpphoBXfYo8rckrHv7Wdo+9/wH8caiAAgJ/I1vD0aQBNx9DB+SS7tAfyRwflMQg/fZj3P3ifww8HJ8JvZZhoxFz8kaZu0vT9dqJVRa95DMK7XqAlPMu0Uj7D0HEbZ5nDr39QT+Oje9h53zba3iz6olI5ZHIauuG9UF+PQTj2Lu92RNAB1u1i75Ot/GLgTXZ9EVgRorWtgUBFkN0/2kt4XYT2vqO0h3XUcD/xn8SIHezBdobpi3fSe/FyzlLa8lJKmV5SGZLHbdQyxeBrHcS+t5P65hj954q2uVr9RlzSsmtdATE77aZa9h4M0f3413hmZDc/PdhAYOpkVWOM/R+gadODL++gPAFqt9cQyCeJ7YtjA4H6Vp6qvfjWdzneFRqO46DyTL8ATO3mTD9d3YNkLnfHvWw5vvW1RMMzb6+VyqEqa2jeEoSPOun45yQKg9rv7iW6bgkmCDw6/mCQgE+D1IWX9dUhQmt90H9R4JxPMWBlgSAbvvUCDes1rJ/UU9/ZRd0dLQR1YFyhFCxfMbO+/o33EK7opXuolx6rGdOfIp0FRpP0HEsTXe3H7u8hu+Z+QpPz41plmIaHw/BwK+1zHUdJbblIRoYY+K8svo2biX47SgCbzsZ6OuI1BL8TnLhAzaPfiKUnwV3O/pjmdErh2xiYPiUyV6tplWzevgO9IkP38210ngJWN7H3kQjGbCeYh0uOyLSbJgNmATSjmmgDVKl+9j/dQcIB/9bv89TWOcLHsel9/Qinc0WvjaZJHHfI7ktPO47lf76Z6Nbg7Mc2T449QNIJ0LT/BRrW65DPkrKz8Fkv+sWf82wrKW4McvcmP92HbfrfSlBjvs2JZQEMbJK/6sX6apjEMYeqB0L4S6lnqW2Zd0h2x+mzx6a9Zh1PouU7OF288sj7BWr+thZz5fQisr8b4MSoSW1DzcQgYVSh/tch8/thcvmi1TSX6Tdi6UlwlzE1YmNnNarMSqbPOC5n+Z9qoBQKLgTgigDhB/xYLzfyxGEbNJOmp5sJ2DG27dFo/dnkCHKqfKXQdG3iRFwiWmWI6BabrpZ6Ok8pqIrS+kiIzMv17Mw0c+jp8PQVFXqAyLdaiBQXku2n46UM0cei858imNXFs7IK+70kGb1ofjub5NcnxzC/EcY/FXbLNDQNcmqWWV2PQTASxn84jn30IPuHHKoebKH62BPEEj0ceSuHlTNpLnWNX4ltiUcnuHUXweIy8mm6n4+jNbUQqbjcDhWZUxY5I0h11UTBKmsxOKzwbjTwFrXR1eg34tIkuMuYSlsMj/uIVPmmv+HRMAwNNTJxu1p8AqmPuuh4KYFCI/RIO7tDOrk30jhaNXpx6I3nyI2A/iVjzttuleol3n2a3GVHV8vxbZx9qgQU6aP7OfBWFjwmTW2tRCoVvf/twI36kt1qzyg3r3Cci4JXpbFO2GhroqybHH2mj79Nwgmwe6OPzHsJnKoQpqbj8yrSIzkUMz8vI1hDuCpOPJWkfzxM+50hgnqQ/cf6iT9vE3jgZ4SuYNXmvNtyMeQV2fMO3oDJ1HelmZMDWMqk7k7zwsBhHv1GLD0J7rKlSA9ZZHSTDTPWDutUBirhrTQ5BcbUyHAkSefeGP0joH15Ny31Jton/XS+0k/u5rvxFre2M4x9XsdcPfdSNK0qQtNjkTnenedRDHXR9lw3acD8egvNIZ3sfx7g4DtptEeW6AnBZV58hg/IoCZHyerDI7x6dOI3QJxzp0kOBQkbKQZtCHxjcs1yPksqcQL1Fw0Eb7Do7U0TXhcCzUfg8xo9f3Cm3+FMWWlSc2eAeMrGCN/P5pt1DO0ewhX9dJ/zE45cwUM7pbTlYvBoVPor0bJMTIOcTxB/ZQjz8XZ2f6WonebRb8TSk+AuV/kMqZNZvOaOWddq+27dgPHz0wydh8BkcDupPo4kJoPqvQ623dbx6fb+9fq0E02ds7A9Js1rlvLxakX6tz0kJr8PtA41cvuhqfd0Irq2NCe/xyDy5D5eDPQwcPSbrN2bxh/ZRdPWIImXk6jEAfY86+Vfn9FQ/jB1k4+f49GpDK7Hlxwg/hps3t4w+dkarPtKFfRaZFRwltGujvlXEczXFeZdk3PuN4a4O+Sn98MwNbeW/hmX0paLQyOwZTdR+yAd3xtAjSznlm/u48WIOe2ic3X6jbisgigv47nCWevjwtl0X+GZv/nLwkP/cnb27cY+Lrz60H2FJ36VuYKdjBU+fuWhwt8921fIjS+otldHpq/wT8/+snB27BrWIX2k8MS9DxV+aV/LSpRo/GzhyLM/KPR8slgFuqzfXMdkHXeZcX7TwYN123jspz1YnhD3bJrjB6S0ADXbTNLv9JX+U5uORe8x2HxvaIketV5knwuxo6lmcZ9aLFVlmOgmRd87tnsePPH4CTc1X9H8+qzc1m+uYxLcZUYLbKY2HEDZOUKPXXo1gLGpiR0rB4hfvDb5khTWm68yuHoH0TUumaX0aBgVSzE9UAqd4IPNBKyumQ/LlDG9wlikkHVhv7mOfaZQKBSudSXEAjgW8R8fwdvQQu1Nlz+h1Kk4sR4vDbtqP50bF/OnUt10vJaj7vGG0n+V0cWk35QXCW4hhHAZmSoRQgiXkeAWQgiXkeAWQgiXkeAWQgiXkeAWQgiXkeAWQgiXkeAWQgiXkeAWQgiXkeAWQgiXkeAWQgiXkeAWQgiX+X+s+iVmQe3Q7AAAAABJRU5ErkJggg==)\n",
        "\n",
        "\n",
        "\n",
        "and where the determinant of the Jacobian can be obtained through\n",
        "\n",
        "\n",
        "![Screenshot from 2025-07-04 00-11-20.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAW4AAABZCAYAAAAeqs4uAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAAAtdEVYdENyZWF0aW9uIFRpbWUARnJpZGF5IDA0IEp1bHkgMjAyNSAxMjoxMToyMCBBTX/VLa8AACAASURBVHic7Z1/bFTnme8/ewfdg8zusUz3jGDXo1D7BDY+CQlDo3SsdDMWW+zQtR0KndC4pq1jN5fYm5BYaaibjesmdUjpBJQ1ZQkOd8NstODQZW0UYnPF9WSLmLYpk2zgmECOE+ixLmhGxZqzF4t3LyPfP2yCbewwNv7BOO9HsgTn53Pe9z3f87zP+7zv/El/f38/EolEIkkb/ttMGyCRSCSS8SGFWyKRSNIMKdwSiUSSZkjhlkgkkjRDCrdEIpGkGVK4JRKJJM2Qwi2RSCRphhRuiUQiSTPmzLQBEslMI86E2PhMO8q9XtxOhNaDNnpxKd75DtGjNgU/301lnjLTZkoknyE97tlK0iG6u57gkXhqx/dG2N6wnciFqTVrsomHt1O/I4KTnOgVBLYZI/8nO9j2XC1VX8tmbm4RNT+qo/aZOmq+VYCh3WqiLbAONNK430TMtCmSGUEK9yzF7mhi1x8LWO/XUjshy0f5StizJYTZN7W2jRdxYjtlf72W4PvO8O1nWggehNIyH6prghdPOsTnLMe/RIWkgxXtgiXL0dWB3Wq2QbZ6c/ZPPgr6qnL0aFPqH2bJrEIK92zkQgfNe2MUfNOHNg5BU70lPOhqpanNmj5PLulgn4gQ+b1FfNSbCuz3jmEpOncuHKKgwqJ1ZyvKygDemxFWl4av2I8nAxAxzG5Brjdv4EPgUjFW+PDcag43gOKh6Ft3Yr2xi0jvTBsjmW6kcKcxoitE4xvRESIrMA/tw8p7mKLccSqO4sEf8OEcasV0bnz4TZOME96ykUe/V0ZZdZDIaM5j0qHLjONZUYpvwbXNzolWWp18Al9LsUeRChe7OBnTMPLcTIlWOyZt+yPEUwzrOO83U/HXOeTk5FD8D9eHRdSlJTykRdl3xJ50UyW3NlK40xaB3WWTuVgfLjJ9FuFwHP1enYk4ompuPsalCJ3TodwuDf8zL1Pj01CXLCdvNA2+aHLM0igo9A55HgezPYJY7BvwlCcJxzpO9xyd5VMVGxEOH39kc/lKaoeryyrZ9ko1RpaOd5nn+o+Jy03evRrd4Qi2DHZ/oZDCna6IGNGPQP/ycJERPVGOn9cwFk1QfNRs9IUO0RP29IRLLpocOy3wLPOOGpJwzpnEPEUULhmy07E49qFDtuGZ0MdpdATW+ybOQi+5t0xMWxAzo9jz8sjXRzNKwa3rKGejdE9HD0lyyyCFO13p7cJK6uRlDd/sfGrSo3jwzB+qgg6RF1eSk5Nz/d99G2jrGXKoKxNPtkLc6rmJTI3Ucc4dx4xnYiwdxaMEQKNgXRH6EM9a9FqYcZXbh8a8nSjBvx36bA+w8cUN3DfkWYu3RIl3NVN25+C25RtouwDxSAvbtzTS1GaSiB0jtLvtulCRONdCxT2jlF9ODsVbR4arxmKcn8JkjOhvLJQl+dfV81UUzYMqLMwLYiD0VPfAcNvqGikbYvcdZc1YF4aW1QNsCkvVTzekcKcBTqSZ+h9upGJNGY2DWQTOpxZikYE7adNScx/3lG3H7BMkLsQQGW7UoSqYFIg+gZpXzo7OU5zq3EZJ9sAufdXD+BYOvZuCOl9FXLBJpNilnziC2IdRrCsKsQPPUla1kY0VxZRtDn8WB1a/EqD8/hExlItxHFS0+UO2qV5qW3/L7nUeADzrGvjxj3bw7/+rAV8GcFc1DY950fIq2fxCCcb9dRz89Q5KFoDmC1D9TAO7O0/xQes26jaUYIx0cC85CJeG/7n9fHDqA/b/nXfgQ5PlJ1BoTE1M/GI30Y8cSJq0/DJI/ZNllP1927CwiJLhxu1yiP1RDISeGt/l3WDhQE8kr5qGTXW8eewg1XcBGT7q6svRF3ipeaUBf14hmzsPs9l/y3QxJCkiJ+Dc6jhRQgdiFDxWhdVQQUvYpMbvw/4khtvwoCgC9wI3nI4RF6AJAXMVlBHZJM4lFe83y/EvcAg3BGnrAWVZNQ1P+K/LPFHmKXApgRjL43YsOva2cjJxY/PnfrmAwGrv6NktIkb0PRMh3Lj9dTSs1hGRetbW7qL1mz4qF48uh+JyAoHCXNeI/S4N7yo/+t4Q1tF/Ixr34TtvEe8DusJ0nqnCe1eCyJFutBU1w7z4GyFEApFdRFWxF840E3wjikCj5EcNBKZoco5zupPoBQWjPEBNhYHS08aGR5po9vtoWDH4MZujoM4RxP7zmpp77n0I/4IO2ro6aDerMDzd2HGgL0r7UZvAYg9WuJ34kofxZd+KKTOSGyGF+1YnqWCsLsfoa6PpdCa+CgP1Soxu2413pQou8H27HH+vIDtjsDN+neAq5BaW8/CiTKz9z/P8XhsyvNQ8V4VvlC74VdEXY3ncqk7hD2opvNln6+3imAnep7fSsFZHQWCfs4m5VNwZExMU1SjCvziEdSbCOxET3osgbtPgnElHu8l61abzrEbBU2OFZkZH0fIJlEOuCNP0XJCIA57VP+XHq8e4zmgftz6byHsO8a32sA/Z6B83gfVelNiCIuqKBzx6IRI4l2I45xIItGv3dYG4cvnaqQu9PHi/h7b9FuFDEYqMd3h/jo6GRfTtDsxVfiJHHXLX+fBMNP9dMqNI4b7VyTLw+xyiW9qxsvzU3q1Bb5iPFR3fYKjAOR8n0+vHo4A9T4H/J4Z7yy4VY1UAT6SRshc7iKPiq66jfGGETaX7MLbsoHyIdyuEgLlzUaa4dTgfHaPLceO/Z1D8RIxI2CTz3h+zbOHY5ylzM1GwuJwUMFI2swyKVhg0nzHp+KcmevpUSp6pxHpxEx1H9tE6z6FnURH+cXqaSraPQLFFS20ZzScE5Aaoe8JH7LUyNsSq2P2cf/gkoNE+bvEwwZ0xAk8FbpwbLmKYJ2IoS6swrtazZdLjKPj+MnPIUwuEUMjMmHvtXJeGt9CPZ38I6/Aumroccr9TS/7RZ2mMtNN6KIGZMKjyTmIqpWRakcKdDogE5gmbTKMGXQXndybCUzggFE6U1kMJ8p8Y8Moy/9yNIhI4AhgaCnCihLaGMAVohXU0VHhRupuxhUq+OlxFnIsCsjyoY4mLY9K2t52PbypUIrBPmMTUPJYPZsaIc2HaP4S8TcvIPBshghffaLno8zXUOQ7xUcfUVIyiIozXTMwTYcyv1NLgK6DHp9FxoI3G1zyUNE5kUo3APtzE9kNxcBlU1tdRmC3o+NSBhep1oambJukQS4D+1dyBek46mEejxLILKLh7iOBecoglVfQvDX8gzVuEPzdEqDtK+IqfzSt8eFUvTUfDhF6y0NftwCd1O22Rwp0OzJmLe0EmidMnsR0fypkEHq8HpTdK6JUWxKpaCgcnp6geHU0cx77EtTBIMk741XqCvxeQ5afmqVL0pEXb6yGiST9VwwYyY/Scdcg2cnGPJUaqQckPjJt7JmETfd9CWbr+s/zt2IfHsFxeag2IHo4iir2jnqpkedBVBzvmANerj5Lrp2hZE+bvFXylhehZGp7iIvQDIaysZTzo84zf3K4W6l9swwaM79ZS5VOJ/247u47YKE9MweCeonJ7dibRwf86H4bY9RuNyheu1TWAE/+YuCubh0bmnmcZFK3QCXVbaP6HKVikoikP4V8Qpu2CB3+hd+LLBEhmHCnc6YBLo/CZrSR2NtH4vTIcR6Actjiek89DlQ34b7umvEq2F6/aimk5fLbIxkWT9sPmwL97w9QX3UH91RPuUoe/wE4PJ8+reNeNLwY8boSDg0HRqmWfxVndS5ZjzGulM9RCfuF6AmOFM+bp5C9R2NVlI1Zo19uZoVNY5GXXOYWi+weeQ7m7CP/iFsTSBxl/hEBg/6b9s5md5u4K7tt9dZ9KoapMflm5PPgfq+T4L5uor4UYOqU/30Zg2VDjBbHTFkIvGCVdUMX4m0KMvQJj5WCPZ6GPB30eOk77KVoqM0nSmn5JWnH5bGv/z37e2R+7MuYR/cdffaR/zQvH+hNjHjM2ifd+0f/I95v6jyduxsqpJ/Hrn/Wv+X5T/8lLM23JOIh19v/ihX39f7g8Sde78of+1qfX9D/b9odJuqAkXZB53GmGY30Meu7ndHMVjJKHyT7TPvraH59H0iHabqKtGiWP+RZD9ZZSlHGc9v9Io8kj832sryzCPUnuuegO847jo/T+8Yd+JOmNFO50IulgdTnoxucvgqTcVkhNieCdt8a3TrXzfoh9F/KpWjnFYZLJIMMg8Gg+9oFpWhBrMnApaAvUySlbYdMR6sS9OjBqSqdkdvMn/f39/TNthGQKSDpEXg9yLLeG2hUpBHV7I2x/NYrxaOW4U+VmkviR7TR1e6l99CbW5E47BNaBIC2ilJp1xiSu1yJJF6RwSyQSSZohQyUSiUSSZkjhlkgkkjRDCrdEIpGkGVK4JRKJJM2Qwi2RSCRphhRuiUQiSTOkcEskEkmaIYVbIpFI0gwp3BKJRJJmSOGWSCSSNEMKt0QikaQZUrglEokkzZDCLZFIJGmGFG6JRCJJM6RwSyQSSZoxJcJdU1MzFZedMWbb80gkkvRm1v7Ku+hqofEfWol+Ggc1F9/3aqldpY/42SiBfaSZ4IHj9JyOoz/+SxpWp8HPdkkkki80s1S4BdbRKO71Ozh4d4zwW2Fi7szrBflCmO1bWmGFD3HUJNYnZsJYiUQiGRezVLhBmROjfW87Jd4A/u/qox4TNzuJOtlUBurY9kzDNFsokUgkE2OWDk4qeB4oIvv9IE+9GiE+6i+dC+yoSUwz0LNkcEQikaQPs1O4+2wiRy0UDaI7NvL8WxZDgyDxI0Eq1hSz4TUT51wb9d9fy4atYwm8RCKR3FrMPuGORwjWPM6+OaX8dPvLBLLjhA+FsYcot7ailt3NDRQtUjG+u5X9v9rPjqd8aK6ZM1sikUhSZXYJd9IhsrORjj+rom6tgaoZ5C/T4GICZ8S4ozhvYl1UyF0is0gkEkl6MbsGJ8+H2XM4RvYTy/AoQFJBVTNRMjNRR6izc/YkPXgoWKTOiKmfR01NDU1NTTNthuRGJB3CL1UQPGfgywX7SAthl5/ACh3OhYmqNex+oTClntx013natLFJLOOpZjrLdFYJt+i1iV/xUJDrHtxgY55O4LnXi3uYcAvs090k5nvRF0p/e1SSDtE3nmfXpYd5+XEf6i3wYkwafSYtr7Qy99u1lOTeqP4F1oEgLclSatcaw3tnjomVWcUvmwrxJE22R8OIb9RS910dum+n+cNc1Cs2bS8F+dhXS80K2bsbN6mU8U20zXh4O02nvNT+IIU23hth+6tRvI9V41sw8XtOBrMqVKJke/FmC+yeGAKIR1pod3xUBQyG+dUihtUVQ1lkkJsxQ8be0gjsQ400hj1UfWeWiXbSIbJzF+bd5SmINoCCvqocPdpE8Eh82B5x0cF9vw+PAuJ8lONxjeVLB8VZ0TB0N4rioeSxhxBvBmnpkvMExktKZTzRa59pIXgQSstSbONZPspXwp4tIcy+Cd50kpgR4bb3b+CenBxycu5jU0f8xiekSpaPmp+Uo7z1FBs2VLBxPwRe+iklt42Mk3QTPQu6b6QnfusjzjRTdmcOOTk5rHwxgjMVN4lHaA7ZFDxRhTdraH2N+Fu+gbYLU2HA1OFEdrHrzJ0EVnhSP0nxUPStO7He2EWkd8jm3EJKlg24BI5l0jPPwLtooEEp2T78dw26C5qf8mJofb1j2CD5LUdSYB8JUhHYRMctUq8pl/F4ERatO1tRVgbwjuMSqreEB12tNLUNz1SbbmZEuD1rd/Db1lq8WXNTP0nYtDQ03rBBqXkBGvbsZ/eO3by5o4HyZUNqpS+O1WUTP2diCZ2Cr6Zf11VZXMmbv36TysXjs9yJbGfTa2YKjU1gHthF5E+LKMwbKDvP2h188MkpDj7jHTTCS23rKT45voOSVLqMjknb/mlMt0zGCW8N0tEzYruwaT8QxV1cijHOnpa6tISHtCj7jtij7BXYXRbkLkcfQwQ8/ofx2nsIvTcln9qbIxmn44creeCbFdRvDRHuuTz+a0x5Hd+4jEc9qytE4xvR69q9c6KVViefwNe08ZmhePAHfDiHWjFnsCpnLlSSoaKMJ8Le20X0TOwmbiiI7qygOPA4P/vXY4ilpfhT6irfgigqyrzx2C6wPziemrfXG6HlX3vIXeVHn6wwknD4+COby1cm6Xo3wrEwxe3kjXgnRU+ETksjf+k4X1YAl5u8ezW6w5Hry1HYmCfiaHfnjd3lVg3yDYeOt8K33nwBl0bhzw/zbutuaicah5/qOk6ljK8/CbvLJnPxyDWKHMz2CGKxD88E2riam49xKULnDCp3WsS4RTxKy5YgrZa4ie6JguerRfiXQM8Fg5pnStHTVLcBUu6rJAX2kSYamyM4KbxUjtlJpDeb5UvdN2PejOJ8FCW2MPe6MFjsw2N0/+nt5M6fyFUV3LqOcjZK98j3Nd7FcVvFuONz4q0ulVxvHnz4v4lOYnTwC0MqZTwSESP6EehfHuGiOxbHPnTINjxMKNCiZqMvdIiesGcsXDJtwi0uhAmuv4877nmA4vUbqP/n49flVjsn2misKWNtaTEr/7aM+gMWIhkn8noToYiFiIcJVq5l7fqNhCYw0KP5qtnxq4Ps311H4ci4961Mn01bw1ruufMeVq4pY8NLLZwcKR7CJrx7ExWBtRT/7UrWPrmdSBzE6RaCOzswewXm3qdYu2YtFZvH8voGuqOJLB1Dm8zyGUdd9Uao//rVOPo9VOy1Eck4bU/e91ls/b7ajs/xWgX2qRjuxSM9R4ee093w557hgt5nsn3NKPH7nBzuWB/CGmK6onlQhYV5YXBjn0XH7iCNW3cR7nEwD+0idDQ+5tO6F92O1tfNyZ5bMFxy06Rex+L97RTfPljOd6xl+wkxer3DuMt4GL1dWEmdvKwR9++1MOMqty8cKtsOkRdXjtoOcu7bQNvQsJsrE0+2QtzqwZmh3tP0CHc8QrC6nui92/j3377LwT0vU77Qwb50LZYmukJsrA5i39/Am60H2f8TL+bWepq7FPybdrD1MR/qAj+1zfvZv2cb5XlpJLw3g7DpePFxmi6U8uavP+Dwr97k5VUq8fNDXv5knPDmx3n2bZWq7fs5+KvXWU8L9Vs6cJaUs21nHaW5Ksa6gVmiuzf5R897TTrEz/YgvuRBm6lsG9Wg8qebCeQO2ebS8Fe/TK1/RIijz6JtyyY21ZSxtiY0EHMUMcz/o2B8WcGJNFK8/IGBAfCkIH7eQdE0lKHPfkWQECqe1Zs5/MEpfru7nIElyTwUrvYPzAcYRMlw43Y5xP44KBsZOoUVtdQFD/LBqXd584Vayu/XxvQIlSwPmiuGZSduspDSG2VJCQ2vVGIMLSjVoLy+gZLbRhycYhk7kWbqf7iRijVlNA5m/zifWohFBu6kTUvNfdxTtn0gG+RiHAcVbWjPKykQfQI1r5wdnac41bmNkuyBXfqqh/EtHPYEqPNVxAWbxHSF/0YwDXncAutQEy1nc6ld5WXAkVPR789H39k9eIxDtC1EhGVs8w/Eo5TF+XjVEJ1hm8q7Rl/d75YhOWB/p5XCoE7m7RR9qwQj68aHAoiuNpoOxchrLPrsHNXIx7soRPjqMT2d7Dlk4fneZrwagIdlX8sl8eo7ROOFFKb6jbtymVj8Moo6zvGHycSl4vF60d0KdF/brC724bvDDeFrcQa7I8QxdznV3hYerWsneiGAoXZjz7kTX5aCctFD9rzL2BcSiCsKl/8LUJThL33SQbh0Sr5dhJ6M0rg1hAXoZXX8uGSE1z5HQZ0jiP3nBDvIikrmPIEVdxAwvljyFLaxaSfDg3fZnWRncC2tzqWi3+vjzr9QaDs3zus5UUIHYhQ8VoXVUEFL2KTG78P+JIbb8KAoAvcCN5yOERfguZxAoDDXNaJPdknF+81y/Ascwg1B2npAWVZNwxPXOzrKPAUuJRAz5HFP/euZdOiKWjhqAZ6R0xevImJYXTbCUXmnOchJBUgKYm6D7BSCUDk5OZNq8ieffDK+E1wq3tXVeCfVChgIXRzHFm78n5O3KD416Y4LiLYQ3KKiAKJXQV8y3hxXgRACMuamHkMfiWPRsbeVk0Odyj6byHsO8a32sBdg7pcLCKz2TnDWm4AFBZT7VLpeCZNYUokvW8H5DxOxqBC3AkpeKeuLj9F5mxtlzhherpJNwbfXoy6I0fZSPc0ngMWVNDwxxmw8F4grE8i6gAHhd4G4NAHhn7I2NgEmo44nU3mSCsbqcoy+NppOZ+KrMFCvxOi23XhXquAC37fL8fcKssfsSSrkFpbz8KJMrP3P8/xeGzK81DxXhW+UD+DVXpuYvR73ZS7/l4AbfZmSwAIv65+oHSWvcnhDFxeiRM578C8b6DqPW2jTCSFIaUjWpZJXWEnd2lHykz/LPRaQdLAiJnh9o2SNKDffIlSdwh/UUjh0WzxMcGeMwFOBYaGH8TO0HBQ8Pj/0tNH0m8sYj/vxZAisTxJ4rk7Q6IthC538v1IBwdz/rgyW5xBvN0PHv86D+VoFz+63QDGofK4K3Wpk7UaFuh1D26NACIXMjAl/1j6zPa2Z0jqeAFkGfp9DdEs7Vpaf2rs16A3zsaLjGwyHOOfjZHoHQ19zM1GwuJwc0hJcKsaqAJ5II2UvdhBHxVddR/nCCJtK92Fs2UH5kBRcIQTMnTtjPdOpv60rE32xByViYzsCRhv0UjwYXzVQ/tnC6hV4r3rm8ShhS8PnG57hIM5H6fxQwbds7HjitJKME32rhU57sruxCpk5Om4s7PNji7eqL2fZwha6rR4cro6UC6yjEYThZ9hE7SsJuo52ouijCPecuWT+WSb0XR5I65rBGZPKyHsnBc7I0WzAOXucrkseAoYbRcTotjPRVw08rx1uIfoXpTQsAFDQNAXR6wx0b4dcX5xpIbgzgkDB98RmanwqiQM2jpI/fI2bSw6xpIr+pQnP1UMkFdTMCZw/ZW1stHvNUK6EECT+77iDSIPnJjBP2GQaNegqOL8zEZ7CgdRBJ0rroQT5Twy8CWK+hjrHIT5yjNiJEtoawhSgFdbRUOFF6W7GFir5I6IFzkUBWZ7r1kCaLqbhe6FifCOAb2+Q9sMWgQ0GiogT/pcWor0x+NDE9vsxVldR+vbztLREKXrah+pyiB5o4VhuLX4UMrM9ZAoL+7xD4nwMRb2FFodyaXjXTU03VvOWErirlT2HOrFWBtAVgXV4Hx1dDgm3iRX34s32s/47Xjb8yz7av+UlkKsgznXQ0pGg1Aug4VkI4Z4eYg7ELmXiHa3BuRSyF6pwwpnRWWHMycStuYHYgGcDiNOt7Dk8MPnFuXCSaJcX/10aynwPGu2ctGIIrWvAy8oYGFdpjupUPn31s6WSrWfDIZuE4Nrga2+U5oZGwr2gfKWG2jID5XyY5n8Kk1j0IJlD3hAn/jFxVzYPpRK/Gw3hEBNz8fzlKD+jdyOmsI2NxpTXv6Lh0YBuMZj7LbDfDdF2AsAhfjqC2ePGm51iSc2Zi3tBJonTJ7EdH8qZBB6vB6U3SuiVFsSqWgoHJ4spWR501cGOOcDggHcyTvjVeoK/F5Dlp+apUvSkRdvrIaJJP1VDzUjG6DnrkG3k4p4h52ZaHH1lcTnb/hEaf7GJ4nZQkgrZebnoWER3VPCdvjc5WF9IQ7NKaGuQtd8QqKpKdkENPx7MJNB8ldSW1NP0wzI6l5ZSV59+sx4nhOql8tUdKFuCPL4mhAKouQa5CyAcbmRtpeDgv1TjfXQHu7Umgk8WE3KpKF8yCGyqG5whqFO6oYrjm5t4tDIb/2MNY3hjKpqRy9ywTU8fn+W52/s3UPzDjmvT60WUYOkdBLMK2fZ2irMnx4NLo3DTVrbp7Rw7/Ch3NNh4CqupXO0l8loUEdnOxhcyORiqRM8rZ+vPBcHdj7P2dYFzRSV6phPvigB1P/IOm6zhXroc7Z9P0nWRz3obTncnrZHBj8Pvg6y9J/jZ8Z5l6pA2JoidthB6wXXpZaki4jZxVzbLR+YVzzgC841naWzrpqfbRDgmP/teMXs8PmpeqMM/FQsqZfmoeWUH7rePceyH95DTreL7QQ0Bv0ow7GC+sYlNGToHn/Gm9p67NAqf2UpiZxON3yvDcQTKYYvjOfk8VNmAf2j67zyd/CUKu7psxIrBXvtFk/bD5sD+3jD1RXdQf/X4u9Thk36cHk6eV/Gum0EN6p8Cqqurp+Ky4+Pi8f5dP/p+/5pvfL3/6yWP9D/5amd/7PLELjXdzzOT5Xf59J7+R/7mkf5d5gQLazRinf2/eGFf/x8m8ZLXk+g/vvP5/j2fZ/flj/v3/I81/c++HRv/5a/8ob/16TX9z7b9YcIWxtqe7P/6N3/Rfzxx/b60b2PTUsepcflsa//Pft7ZH7sy9jGJX/+sf833m/pPXhr/9RPv/aL/ke83XVeP01mHaTFzciI4ZifWklrebN3P1scKuHORNnMpbmmEcpuPIt3h+Iexyesuz/exvrJoahf06rMxY26Mz1umV9EpWmtgH+kc92JPojvMO46P0vvHsTjVUJJxzN91o/kLMG41h3symI46ThHH+hj0z1/uVfWWUpRxnPb/GOdkqKRDtN1EW1Uyo/U4a4WbuWC1tRCOqxirKqksNmbX8qRThaJTVGwQfzeMPVlLV7oUtAXqlHYrxXkTe56B5wYvk3Z/JeuzjhEKj2PeubDpCHXiXh0YNTUsJc5HaD+dTekqY3aG+KahjlMi6WB1OejGDVJhMwwCj+ZjHxjfYlHO+yH2XcinauXMhmpnrXCri4somNfO83/fTHSwYuIdG7lvtCmtOQ9QH56N05AnhraimkDWcTpOp0+ZKLkB6p4aY0bosAM9FD5Rhee9XbSdS8XtFliHQpw0aqldNUFvG4fowXdIFNVQmq4Lm6ULLhXf3zUQSGH1THVZJT8udGjZG0lt6npvhNDb8PCm8hnvNc1O4U46WJEIsXluxJFGnto8sLbF5f8UoPmo3vNbOTghrAAAAkVJREFUTp08TIN/oPSVrwQoHc+ivLMdxUPp4w9x+V9DRGbjgkiqQflzddev0z4qCvrqOurWGRNbkIjBJUT/WEDtulnqbacx2opqGlL59RuALB/V9dX4U810mUJmn3CLOB0vVbDpXTeVL/+SukIV+8i/ETkvEJcE7q8+TOBeFbstSFPYgSwftT+pHNdi6l8ElGw/Vd/WMN81p+bHGr4oCJtoVKH0scDkLZMr+cIz64br7MNBgr8xqPufJXhUgbjfixpxiPWBz3iI8tvymHuimU2bB2ZH+Z9u+OIsWDVO1LwAlXkzbUWao3jwf3eiIRaJZHRml8ctLMJvdSLy8jHmAygoGQpKhoo7Q0H7SgmBv+om+KMgEQe0VXXUrVJo3VDMxgOj/bLJzJAWv74tmVSmu85lG5t8prNMZ5dw98WxL0Lu3YOpQEmHHrMb9OXkzWdgdlRzkJZu4LYAP90UQHf1YMUgMytzho2XSCSS1Jhdwq3qLF/qxvl0YIFz0RNm31GFoopS9AyB3RakfrcFeAg8XY1/oYN5YBet3Uxs/QiJRCKZAWZXjNulUfhMA/aLQTZW7UO5Avpjm6n5mgZJm8jhdgYCIjYtTz5Ay5OD52X4cM+bObMlEolkPMwu4QbI8lIZfJPK63Z4COz4gMAMmCSRSCSTyewKlUgkEskXACncEolEkmZI4ZZIJJI040/6+/v7Z9oIiUQikaSO9LglEokkzZDCLZFIJGmGFG6JRCJJM6RwSyQSSZohhVsikUjSDCncEolEkmb8fzIxJOMknMFcAAAAAElFTkSuQmCC)\n",
        "\n",
        "\n",
        "\n",
        "This led to our first implementation of the PlanarFlow. Note here that we added a little bonus that we can change the non-linearity h used in the flow directly in its initialization."
      ],
      "metadata": {
        "id": "2rLeBaOdlwmF"
      },
      "id": "2rLeBaOdlwmF"
    },
    {
      "cell_type": "code",
      "source": [
        "class PlanarFlow(Flow):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "    def __init__(self, dim, h=torch.tanh, hp=(lambda x: 1 - torch.tanh(x) ** 2)):\n",
        "        super(PlanarFlow, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(1, dim))\n",
        "        self.scale = nn.Parameter(torch.Tensor(1, dim))\n",
        "        self.bias = nn.Parameter(torch.Tensor(1))\n",
        "        self.h = h\n",
        "        self.hp = hp\n",
        "        self.init_parameters()\n",
        "\n",
        "    def _call(self, z):\n",
        "        f_z = F.linear(z, self.weight, self.bias)\n",
        "        return z + self.scale * self.h(f_z)\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        f_z = F.linear(z, self.weight, self.bias)\n",
        "        psi = self.hp(f_z) * self.weight\n",
        "        det_grad = 1 + torch.mm(psi, self.scale.t())\n",
        "        return torch.log(det_grad.abs() + 1e-9)"
      ],
      "metadata": {
        "id": "BF_iQHJtlRlj"
      },
      "id": "BF_iQHJtlRlj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def change_density(q0_density, flow, z):\n",
        "    # Apply our transform on coordinates\n",
        "    f_z = flow(torch.Tensor(z)).detach()\n",
        "    # Obtain our density\n",
        "    q1_density = q0_density.squeeze() / np.exp(flow.log_abs_det_jacobian(torch.Tensor(z)).detach().squeeze())\n",
        "    return q1_density, f_z"
      ],
      "metadata": {
        "id": "FXyoNRQbmg7q"
      },
      "id": "FXyoNRQbmg7q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our base density\n",
        "q0 = distrib.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "q0_density = torch.exp(q0.log_prob(torch.Tensor(z)))\n",
        "# Our transform\n",
        "flow = PlanarFlow(2)\n",
        "# Manually set the transform parameters (I know it is dirty ^^)\n",
        "flow.weight.data = torch.Tensor([[4, 0]])\n",
        "flow.scale.data = torch.Tensor([[2, 0]])\n",
        "flow.bias.data = torch.Tensor([0])\n",
        "q1_density, f_z = change_density(q0_density, flow, z)\n",
        "# Plot this\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 5))\n",
        "ax1.hexbin(z[:,0], z[:,1], C=q0_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax1.set_title('$q_0 = \\mathcal{N}(\\mathbf{0},\\mathbb{I})$', fontsize=18);\n",
        "ax2.hexbin(f_z[:,0], f_z[:,1], C=q1_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax2.set_title('$q_1=planar(q_0)$', fontsize=18);"
      ],
      "metadata": {
        "id": "23LJiz5am2sC"
      },
      "id": "23LJiz5am2sC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"recap\"></a>\n",
        "# Radial flow\n",
        "\n",
        "We will start our tour of different types of flows recently introduced by re-implementing the *radial flow*, proposed in the original paper by Rezende [1]. This family of transformations aim to modify the initial density $q_0$ around a reference point $\\mathbf{z}_0$\n",
        "\n",
        "   $$\n",
        "   f(\\mathbf{z})=\\mathbf{z}+\\beta h(\\alpha,r)(\\mathbf{z}-\\mathbf{z}_0)\n",
        "   \\tag{7}\n",
        "   $$\n",
        "\n",
        "   where $\\beta$ is a scalar, $\\alpha$ is a positive scalar $r=\\left\\lVert\\mathbf{z}-\\mathbf{z}_0\\right\\rVert$ and $h(\\alpha,r)=1/(\\alpha+r)$. As recalled in the beginning of the tutorial, in order to obtain the actual density of $f(\\mathbf{z})$, we need to compute the determinant of the Jacobian $\\left|\\det\\frac{\\partial f}{\\partial \\mathbf{z}}\\right|$. This can be computed as follows (the full derivation once again relies on the matrix determinant lemma, for a full\n",
        "\n",
        "$$\n",
        "\\left|\\det\\frac{\\partial f}{\\partial \\mathbf{z}}\\right| = \\left(1 + \\beta h(\\alpha,r) + \\beta h'(\\alpha,r)r\\right)(1+\\beta h(\\alpha,r))^{d-1}\n",
        "\\tag{8}\n",
        "$$\n",
        "   \n",
        "This type of flow also provides a computation of the determinant in $O(D)$, but applies radial contractions and expansions around the reference point (hence the name *radial\n",
        "flows*). Here, we will implement the `RadialFlow` by following our previously defined `Flow` class"
      ],
      "metadata": {
        "id": "utlAh1ANtEYO"
      },
      "id": "utlAh1ANtEYO"
    },
    {
      "cell_type": "code",
      "source": [
        "class RadialFlow(Flow):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(RadialFlow, self).__init__()\n",
        "        self.z0 = nn.Parameter(torch.Tensor(1, dim))\n",
        "        self.alpha = nn.Parameter(torch.Tensor(1))\n",
        "        self.beta = nn.Parameter(torch.Tensor(1))\n",
        "        self.dim = dim\n",
        "        self.init_parameters()\n",
        "\n",
        "    def _call(self, z):\n",
        "        r = torch.norm(z - self.z0, dim=1).unsqueeze(1)\n",
        "        h = 1 / (self.alpha + r)\n",
        "        return z + (self.beta * h * (z - self.z0))\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        r = torch.norm(z - self.z0, dim=1).unsqueeze(1)\n",
        "        h = 1 / (self.alpha + r)\n",
        "        hp = - 1 / (self.alpha + r) ** 2\n",
        "        bh = self.beta * h\n",
        "        det_grad = ((1 + bh) ** self.dim - 1) * (1 + bh + self.beta * hp * r)\n",
        "        return torch.log(det_grad.abs() + 1e-9)"
      ],
      "metadata": {
        "id": "QOcK8pprpdhQ"
      },
      "id": "QOcK8pprpdhQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our base density\n",
        "q0 = distrib.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "q0_density = torch.exp(q0.log_prob(torch.Tensor(z)))\n",
        "# Our transform\n",
        "flow = RadialFlow(2)\n",
        "# Manually set the transform parameters (I know it is dirty ^^)\n",
        "flow.z0.data = torch.Tensor([[0.5, 0.5]])\n",
        "flow.alpha.data = torch.Tensor([1])\n",
        "flow.beta.data = torch.Tensor([8])\n",
        "q1_density, f_z = change_density(q0_density, flow, z)\n",
        "# Plot this\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax1.hexbin(z[:,0], z[:,1], C=q0_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax1.set_title('$q_0 = \\mathcal{N}(\\mathbf{0},\\mathbb{I})$', fontsize=18);\n",
        "ax2.hexbin(f_z[:,0], f_z[:,1], C=q1_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax2.set_title('$q_1=radial(q_0)$', fontsize=18);"
      ],
      "metadata": {
        "id": "WN2ZYb1PpryC"
      },
      "id": "WN2ZYb1PpryC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchNormFlow(Flow):\n",
        "\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "\n",
        "    def __init__(self, dim, momentum=0.95, eps=1e-5):\n",
        "        super(BatchNormFlow, self).__init__()\n",
        "        # Running batch statistics\n",
        "        self.r_mean = torch.zeros(dim)\n",
        "        self.r_var = torch.ones(dim)\n",
        "        # Momentum\n",
        "        self.momentum = momentum\n",
        "        self.eps = eps\n",
        "        # Trainable scale and shift (cf. original paper)\n",
        "        self.gamma = nn.Parameter(torch.ones(dim))\n",
        "        self.beta = nn.Parameter(torch.zeros(dim))\n",
        "\n",
        "    def _call(self, z):\n",
        "        if self.training:\n",
        "            # Current batch stats\n",
        "            self.b_mean = z.mean(0)\n",
        "            self.b_var = (z - self.b_mean).pow(2).mean(0) + self.eps\n",
        "            # Running mean and var\n",
        "            self.r_mean = self.momentum * self.r_mean + ((1 - self.momentum) * self.b_mean)\n",
        "            self.r_var = self.momentum * self.r_var + ((1 - self.momentum) * self.b_var)\n",
        "            mean = self.b_mean\n",
        "            var = self.b_var\n",
        "        else:\n",
        "            mean = self.r_mean\n",
        "            var = self.r_var\n",
        "        x_hat = (z - mean) / var.sqrt()\n",
        "        y = self.gamma * x_hat + self.beta\n",
        "        return y\n",
        "\n",
        "    def _inverse(self, x):\n",
        "        if self.training:\n",
        "            mean = self.b_mean\n",
        "            var = self.b_var\n",
        "        else:\n",
        "            mean = self.r_mean\n",
        "            var = self.r_var\n",
        "        x_hat = (z - self.beta) / self.gamma\n",
        "        y = x_hat * var.sqrt() + mean\n",
        "        return y\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        # Here we only need the variance\n",
        "        mean = z.mean(0)\n",
        "        var = (z - mean).pow(2).mean(0) + self.eps\n",
        "        log_det = torch.log(self.gamma) - 0.5 * torch.log(var + self.eps)\n",
        "        return torch.sum(log_det, -1)"
      ],
      "metadata": {
        "id": "PqgV3vGWprQX"
      },
      "id": "PqgV3vGWprQX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define grids of points (for later plots)\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
        "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])"
      ],
      "metadata": {
        "id": "PLfLjQee3LzQ"
      },
      "id": "PLfLjQee3LzQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our base density\n",
        "q0 = distrib.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "q0_density = torch.exp(q0.log_prob(torch.Tensor(z)))\n",
        "# Our BatchNorm transform\n",
        "flow = BatchNormFlow(2)\n",
        "flow.momentum = torch.Tensor([1000])\n",
        "flow.r_mean = torch.Tensor([[3.0,5.0]])\n",
        "\n",
        "q1_density, f_z = change_density(q0_density, flow, z)\n",
        "\n",
        "# Plot this\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "ax1.hexbin(z[:,0], z[:,1], C=q0_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax1.set_title('$q_0 = \\mathcal{N}(\\mathbf{0},\\mathbb{I})$', fontsize=18);\n",
        "ax2.set_xlim([-4, 4])\n",
        "ax2.set_ylim([-4, 4])\n",
        "ax2.hexbin(f_z[:,0], f_z[:,1], C=q1_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax2.set_title('$q_1=BatchNorm(q_0)$', fontsize=18);\n"
      ],
      "metadata": {
        "id": "_Oopt3Ij0OI3"
      },
      "id": "_Oopt3Ij0OI3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parametric ReLU flow\n",
        "Although this is very similar to the base ReLU (and is more generally a form of Leaky ReLU), it comes with the added bonus of having a trainable parameters. The PReLU is defined as\n",
        "\n",
        "$$\n",
        "\\text{PReLU}\\left(x\\right)=\n",
        "\\begin{cases}\n",
        "    x,& \\text{if } x > 0\\\\\n",
        "    \\alpha . x,              & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The first advantage of this non-linearity is that its derivative is extremely simple. And as we have just seen for element-wise operations, we can obtain the log-determinant of its Jacobian simply as\n",
        "\n",
        "$$\n",
        "\\text{log }\\left|\\det{\\frac{\\partial f}{\\partial \\mathbf{x}}}\\right| = \\sum_{i=1}^D \\text{log }\\left|\n",
        "\\begin{cases}\n",
        "    1,& \\text{if } x > 0\\\\\n",
        "    \\alpha ,              & \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\right|\n",
        "$$\n",
        "\n",
        "The second advantage of the PReLU is that it is now also invertible and we can define\n",
        "\n",
        "$$\n",
        "\\text{PReLU}^{-1}\\left(x\\right)=\n",
        "\\begin{cases}\n",
        "    x,& \\text{if } x > 0\\\\\n",
        "    \\frac{1}{\\alpha} . x,              & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Hence, we have all the elements to consider this transform as a flow, and we define here the `PReLUFlow` following our base architecture."
      ],
      "metadata": {
        "id": "xk-Ip1l_t8Q9"
      },
      "id": "xk-Ip1l_t8Q9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Flow version of Leaky ReLU\n",
        "class PReLUFlow(Flow):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = True\n",
        "    event_dim = 1\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(PReLUFlow, self).__init__()\n",
        "        self.alpha = nn.Parameter(torch.Tensor([1]))\n",
        "        self.bijective = True\n",
        "\n",
        "    def init_parameters(self):\n",
        "        for param in self.parameters():\n",
        "            param.data.uniform_(0.01, 0.99)\n",
        "\n",
        "    def _call(self, z):\n",
        "        return torch.where(z >= 0, z, torch.abs(self.alpha) * z)\n",
        "\n",
        "    def _inverse(self, z):\n",
        "        return torch.where(z >= 0, z, torch.abs(1. / self.alpha) * z)\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        I = torch.ones_like(z)\n",
        "        J = torch.where(z >= 0, I, self.alpha * I)\n",
        "        log_abs_det = torch.log(torch.abs(J) + 1e-5)\n",
        "        return torch.sum(log_abs_det, dim = 1)"
      ],
      "metadata": {
        "id": "7qivJwRb2Usd"
      },
      "id": "7qivJwRb2Usd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our base density\n",
        "q0 = distrib.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "q0_density = torch.exp(q0.log_prob(torch.Tensor(z)))\n",
        "\n",
        "# Our Batchnorm transform\n",
        "flow = BatchNormFlow(2)\n",
        "\n",
        "q1_density, f_z = change_density(q0_density, flow, z)\n",
        "# Our ReLU flow\n",
        "flow = PReLUFlow(2)\n",
        "# Manually set the transform parameters (dirty again ^^)\n",
        "flow.alpha.data = torch.Tensor([0.5])\n",
        "q2_density, f_z2 = change_density(q1_density, flow, f_z)\n",
        "\n",
        "# Plot this\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "ax1.hexbin(z[:,0], z[:,1], C=q0_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax1.set_title('$q_0 = \\mathcal{N}(\\mathbf{0},\\mathbb{I})$', fontsize=18);\n",
        "ax2.hexbin(f_z[:,0], f_z[:,1], C=q1_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax2.set_title('$q_1=BatchNorm(q_0)$', fontsize=18);\n",
        "ax3.hexbin(f_z2[:,0], f_z2[:,1], C=q2_density.numpy().squeeze(), cmap='rainbow')\n",
        "ax3.set_title('$q_2=PReLU(q_1)$', fontsize=18);"
      ],
      "metadata": {
        "id": "aPHx3nCj6NA1"
      },
      "id": "aPHx3nCj6NA1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Flow version of affine transform\n",
        "class AffineFlow(Flow):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super(AffineFlow, self).__init__()\n",
        "        self.weights = nn.Parameter(torch.Tensor(dim, dim))\n",
        "        nn.init.orthogonal_(self.weights)\n",
        "\n",
        "    def _call(self, z):\n",
        "        return z @ self.weights\n",
        "\n",
        "    def _inverse(self, z):\n",
        "        return z @ torch.inverse(self.weights)\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        return torch.slogdet(self.weights)[-1].unsqueeze(0).repeat(z.size(0), 1)"
      ],
      "metadata": {
        "id": "iqH0lZny9xit"
      },
      "id": "iqH0lZny9xit",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import linalg as splin\n",
        "## Affine Flow with LU decomposition\n",
        "class AffineLUFlow(Flow):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "    def __init__(self, dim):\n",
        "        super(AffineLUFlow, self).__init__()\n",
        "        weights = torch.Tensor(dim, dim)\n",
        "        nn.init.orthogonal_(weights)\n",
        "        # Compute the parametrization\n",
        "        P, L, U = splin.lu(weights.numpy())\n",
        "        self.P = torch.Tensor(P)\n",
        "        self.L = nn.Parameter(torch.Tensor(L))\n",
        "        self.U = nn.Parameter(torch.Tensor(U))\n",
        "        # Need to create masks for enforcing triangular matrices\n",
        "        self.mask_low = torch.tril(torch.ones(weights.size()), -1)\n",
        "        self.mask_up = torch.triu(torch.ones(weights.size()), -1)\n",
        "        self.I = torch.eye(weights.size(0))\n",
        "        # Now compute s\n",
        "        self.s = nn.Parameter(torch.Tensor(np.diag(np.array(U))))\n",
        "\n",
        "    def _call(self, z):\n",
        "        L = self.L * self.mask_low + self.I\n",
        "        U = self.U * self.mask_up + torch.diag(self.s)\n",
        "        weights = self.P @ L @ U\n",
        "        return z @ weights\n",
        "\n",
        "    def _inverse(self, z):\n",
        "        L = self.L * self.mask_low + self.I\n",
        "        U = self.U * self.mask_up + torch.diag(self.s)\n",
        "        weights = self.P @ L @ U\n",
        "        return z @ torch.inverse(self.weights)\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        return torch.sum(torch.log(torch.abs(self.s))).unsqueeze(0).repeat(z.size(0), 1)"
      ],
      "metadata": {
        "id": "BhY4FEPK6T1Z"
      },
      "id": "BhY4FEPK6T1Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main class for normalizing flow\n",
        "class NormalizingFlow(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, blocks, flow_length, density):\n",
        "        super().__init__()\n",
        "        biject = []\n",
        "        for f in range(flow_length):\n",
        "            for b_flow in blocks:\n",
        "                biject.append(b_flow(dim))\n",
        "        self.transforms = transform.ComposeTransform(biject)\n",
        "        self.bijectors = nn.ModuleList(biject)\n",
        "        self.base_density = density\n",
        "        self.final_density = distrib.TransformedDistribution(density, self.transforms)\n",
        "        self.log_det = []\n",
        "\n",
        "    def forward(self, z):\n",
        "        self.log_det = []\n",
        "        # Applies series of flows\n",
        "        for b in range(len(self.bijectors)):\n",
        "            self.log_det.append(self.bijectors[b].log_abs_det_jacobian(z))\n",
        "            z = self.bijectors[b](z)\n",
        "        return z, self.log_det"
      ],
      "metadata": {
        "id": "PovJKhx69dPa"
      },
      "id": "PovJKhx69dPa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our MLP blocks\n",
        "block_mlp = [\n",
        "    PlanarFlow,\n",
        "    BatchNormFlow,\n",
        "    PReLUFlow\n",
        "]\n",
        "# Create normalizing flow\n",
        "flow = NormalizingFlow(dim=2, blocks=block_mlp, flow_length=10, density=distrib.MultivariateNormal(torch.zeros(2), torch.eye(2)))"
      ],
      "metadata": {
        "id": "VU29-OTo9joR"
      },
      "id": "VU29-OTo9joR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def density_ring(z):\n",
        "    z1, z2 = torch.chunk(z, chunks=2, dim=1)\n",
        "    norm = torch.sqrt(z1 ** 2 + z2 ** 2)\n",
        "    exp1 = torch.exp(-0.5 * ((z1 - 2) / 0.8) ** 2)\n",
        "    exp2 = torch.exp(-0.5 * ((z1 + 2) / 0.8) ** 2)\n",
        "    u = 0.5 * ((norm - 4) / 0.4) ** 2 - torch.log(exp1 + exp2)\n",
        "    return torch.exp(-u)\n",
        "\n",
        "# Plot it\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
        "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])\n",
        "plt.hexbin(z[:,0], z[:,1], C=density_ring(torch.Tensor(z)).numpy().squeeze(), cmap='rainbow')\n",
        "plt.title('Target density', fontsize=18);"
      ],
      "metadata": {
        "id": "PySQZCpK97GZ"
      },
      "id": "PySQZCpK97GZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Create optimizer algorithm\n",
        "optimizer = optim.Adam(flow.parameters(), lr=1e-3)\n",
        "# Add learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.99995)\n",
        "# Define our loss\n",
        "def loss(density, zk, log_jacobians):\n",
        "    sum_of_log_jacobians = sum(log_jacobians)\n",
        "    return (-sum_of_log_jacobians - torch.log(density(zk) + 1e-9)).mean()"
      ],
      "metadata": {
        "id": "R_Wm7WLY--zD"
      },
      "id": "R_Wm7WLY--zD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_distrib = distrib.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "id_figure=2\n",
        "plt.figure(figsize=(16, 18))\n",
        "plt.subplot(3,4,1)\n",
        "plt.hexbin(z[:,0], z[:,1], C=density_ring(torch.Tensor(z)).numpy().squeeze(), cmap='rainbow')\n",
        "plt.title('Target density', fontsize=15);\n",
        "# Main optimization loop\n",
        "for it in range(10001):\n",
        "    # Draw a sample batch from Normal\n",
        "    samples = ref_distrib.sample((512, ))\n",
        "    # Evaluate flow of transforms\n",
        "    zk, log_jacobians = flow(samples)\n",
        "    # Evaluate loss and backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss_v = loss(density_ring, zk, log_jacobians)\n",
        "    loss_v.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    if (it % 1000 == 0):\n",
        "        print('Loss (it. %i) : %f'%(it, loss_v.item()))\n",
        "        # Draw random samples\n",
        "        samples = ref_distrib.sample((int(1e5), ))\n",
        "        # Evaluate flow and plot\n",
        "        zk, _ = flow(samples)\n",
        "        zk = zk.detach().numpy()\n",
        "        plt.subplot(3,4,id_figure)\n",
        "        plt.hexbin(zk[:,0], zk[:,1], cmap='rainbow')\n",
        "        plt.title('Iter.%i'%(it), fontsize=15);\n",
        "        id_figure += 1"
      ],
      "metadata": {
        "id": "mW32ax9W_DWM"
      },
      "id": "mW32ax9W_DWM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as distrib\n",
        "import torch.distributions.transforms as transform\n",
        "# Imports for plotting\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Define grids of points (for later plots)\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
        "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])"
      ],
      "metadata": {
        "id": "bs7i90iIz56z"
      },
      "id": "bs7i90iIz56z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = lambda z: torch.sin(2 * math.pi * z[:, 0] / 4)\n",
        "w2 = lambda z: 3 * torch.exp(-0.5 * ((z[:, 0] - 1) / 0.6) ** 2)\n",
        "w3 = lambda z: 3 * (1.0 / (1 + torch.exp(-(z[:, 0] - 1) / 0.3)))\n",
        "\n",
        "def density_mvn(z, mu=torch.FloatTensor([[0, 0]]), sig=torch.FloatTensor([[1, 1]])):\n",
        "    z = z[:, None, :] - mu[None, :, :]\n",
        "    sig_inv = 1./sig\n",
        "    exponent = -0.5 * torch.sum(z * sig_inv[None, :, :] * z, (1, 2))\n",
        "    return torch.exp(exponent)\n",
        "\n",
        "def density_bivar(z):\n",
        "    add1 = 0.5 * ((torch.norm(z, 2, 1) - 2) / 0.4) ** 2\n",
        "    add2 = -torch.log(torch.exp(-0.5 * ((z[:, 0] - 2) / 0.6) ** 2) + torch.exp(-0.5 * ((z[:, 0] + 2) / 0.6) ** 2))\n",
        "    return torch.exp(-(add1 + add2))\n",
        "\n",
        "def density_ring(z):\n",
        "    z1, z2 = torch.chunk(z, chunks=2, dim=1)\n",
        "    norm = torch.sqrt(z1 ** 2 + z2 ** 2)\n",
        "    exp1 = torch.exp(-0.5 * ((z1 - 2) / 0.8) ** 2)\n",
        "    exp2 = torch.exp(-0.5 * ((z1 + 2) / 0.8) ** 2)\n",
        "    u = 0.5 * ((norm - 4) / 0.4) ** 2 - torch.log(exp1 + exp2)\n",
        "    return torch.exp(-u)\n",
        "\n",
        "def density_wave(z):\n",
        "    z = torch.reshape(z, [z.shape[0], 2])\n",
        "    z1, z2 = z[:, 0], z[:, 1]\n",
        "    u = 0.5 * ((z2 - w1(z))/0.4) ** 2\n",
        "    u[torch.abs(z1) > 4] = 1e8\n",
        "    return torch.exp(-u)\n",
        "\n",
        "def density_wave_twist(z):\n",
        "    in1 = torch.exp(-0.5 * ((z[:, 1] - w1(z)) / 0.35) ** 2)\n",
        "    in2 = torch.exp(-0.5 * ((z[:, 1] - w1(z) + w2(z)) / 0.35) ** 2)\n",
        "    return torch.exp(torch.log(in1 + in2 + 1e-9))\n",
        "\n",
        "def density_wave_split(z):\n",
        "    in1 = torch.exp(-0.5 * ((z[:, 1] - w1(z)) / 0.4) ** 2)\n",
        "    in2 = torch.exp(-0.5 * ((z[:, 1] - w1(z) + w3(z)) / 0.35) ** 2)\n",
        "    return torch.exp(torch.log(in1 + in2))\n",
        "\n",
        "def density_circle(z, n_dens=10):\n",
        "    full_dens = []\n",
        "    for n in range(n_dens):\n",
        "        x = math.cos((n / float(n_dens)) * 2 * math.pi) * 3\n",
        "        y = math.sin((n / float(n_dens)) * 2 * math.pi) * 3\n",
        "        full_dens.append(density_mvn(z, mu=torch.FloatTensor([[x, y]]), sig= 0.1 * torch.FloatTensor([[1, 2]])).unsqueeze(1))\n",
        "    return torch.sum(torch.cat(full_dens, dim=1), dim=1)\n",
        "\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
        "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])\n",
        "# Set of target densities\n",
        "targets = [density_bivar, density_ring, density_wave, density_wave_twist, density_wave_split, density_circle]\n",
        "# Plot these lads\n",
        "plt.figure(figsize=(15, 5))\n",
        "for t in range(len(targets)):\n",
        "    plt.subplot(1, len(targets), t+1)\n",
        "    plt.hexbin(z[:,0], z[:,1], C = targets[t](torch.Tensor(z)).numpy().squeeze(), cmap='rainbow')\n",
        "    plt.title('Target ' + str(t), fontsize=18);"
      ],
      "metadata": {
        "id": "uvZTkITh_OOY"
      },
      "id": "uvZTkITh_OOY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flow(transform.Transform, nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        transform.Transform.__init__(self)\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "    # Init all parameters\n",
        "    def init_parameters(self):\n",
        "        for param in self.parameters():\n",
        "            param.data.uniform_(-0.01, 0.01)\n",
        "\n",
        "    # Hacky hash bypass\n",
        "    def __hash__(self):\n",
        "        return nn.Module.__hash__(self)"
      ],
      "metadata": {
        "id": "ZqJO8JB91ESk"
      },
      "id": "ZqJO8JB91ESk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Define our loss\n",
        "def loss(density, zk, log_jacobians):\n",
        "    sum_of_log_jacobians = sum(log_jacobians)\n",
        "    return (-sum_of_log_jacobians - torch.log(density(zk) + 1e-9)).mean()"
      ],
      "metadata": {
        "id": "PPbw80kqz-VK"
      },
      "id": "PPbw80kqz-VK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_flow(flow, loss, optimizer, scheduler, target_density, epochs=10001, plot_it=1000):\n",
        "    ref_distrib = distrib.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "    ims = []\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 7))\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    # Main optimization loop\n",
        "    for it in range(epochs):\n",
        "        # Draw a sample batch from Normal\n",
        "        samples = ref_distrib.sample((512, ))\n",
        "        # Evaluate flow of transforms\n",
        "        zk, log_jacobians = flow(samples)\n",
        "        # Evaluate loss and backprop\n",
        "        #optimizer.zero_grad()\n",
        "        loss_v = loss(target_density, zk, log_jacobians)\n",
        "        loss_v.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if (it % plot_it == 0):\n",
        "            print('Loss (it. %i) : %f'%(it, loss_v.item()))\n",
        "            # Draw random samples\n",
        "            samples = ref_distrib.sample((int(1e5), ))\n",
        "            # Evaluate flow and plot\n",
        "            zk, _ = flow(samples)\n",
        "            zk = zk.detach().numpy()\n",
        "            im = plt.hexbin(zk[:,0], zk[:,1], cmap='rainbow', animated='True')\n",
        "            ims.append([im])\n",
        "    ax1.hexbin(z[:,0], z[:,1], C=target_density(torch.Tensor(z)).numpy().squeeze(), cmap='rainbow')\n",
        "    ax1.set_title('Target density', fontsize=15);\n",
        "    ax2.hexbin(zk[:,0], zk[:,1], cmap='rainbow')\n",
        "    ax2.set_title('Final approximation', fontsize=15)\n",
        "    # anim = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "    # HTML(anim.to_html5_video())\n",
        "    # anim.save(\"check.mp4\")\n",
        "    ax3.set_title('Optimization process', fontsize=15)"
      ],
      "metadata": {
        "id": "Rp-t99mk0MKv"
      },
      "id": "Rp-t99mk0MKv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions import MultivariateNormal, TransformedDistribution, constraints, Transform\n",
        "# Affine coupling flow\n",
        "class AffineCouplingFlow(Flow):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "\n",
        "    def __init__(self, dim, n_hidden=64, n_layers=3, activation=nn.ReLU):\n",
        "        super(AffineCouplingFlow, self).__init__()\n",
        "        self.k = dim // 2\n",
        "        self.g_mu = self.transform_net(self.k, dim - self.k, n_hidden, n_layers, activation)\n",
        "        self.g_sig = self.transform_net(self.k, dim - self.k, n_hidden, n_layers, activation)\n",
        "        self.init_parameters()\n",
        "        self.bijective = True\n",
        "\n",
        "    def transform_net(self, nin, nout, nhidden, nlayer, activation):\n",
        "        net = nn.ModuleList()\n",
        "        for l in range(nlayer):\n",
        "            net.append(nn.Linear(l==0 and nin or nhidden, l==nlayer-1 and nout or nhidden))\n",
        "            net.append(activation())\n",
        "        return nn.Sequential(*net)\n",
        "\n",
        "    def _call(self, z):\n",
        "        z_k, z_D = z[:, :self.k], z[:, self.k:]\n",
        "        zp_D = z_D * torch.exp(self.g_sig(z_k)) + self.g_mu(z_k)\n",
        "        return torch.cat((z_k, zp_D), dim = 1)\n",
        "\n",
        "    def _inverse(self, z):\n",
        "        zp_k, zp_D = z[:, :self.k], z[:, self.k:]\n",
        "        z_D = (zp_D - self.g_mu(zp_k)) / self.g_sig(zp_k)\n",
        "        return torch.cat((zp_k, z_D))\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        z_k = z[:, :self.k]\n",
        "        return -torch.sum(torch.abs(self.g_sig(z_k)))"
      ],
      "metadata": {
        "id": "Nc8BhLBD0RDb"
      },
      "id": "Nc8BhLBD0RDb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReverseFlow(Flow):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "    def __init__(self, dim):\n",
        "        super(ReverseFlow, self).__init__()\n",
        "        self.permute = torch.arange(dim-1, -1, -1)\n",
        "        self.inverse = torch.argsort(self.permute)\n",
        "\n",
        "    def _call(self, z):\n",
        "        return z[:, self.permute]\n",
        "\n",
        "    def _inverse(self, z):\n",
        "        return z[:, self.inverse]\n",
        "\n",
        "    def log_abs_det_jacobian(self, z):\n",
        "        return torch.zeros(z.shape[0], 1)"
      ],
      "metadata": {
        "id": "c4tYvwja0WVQ"
      },
      "id": "c4tYvwja0WVQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShuffleFlow(ReverseFlow):\n",
        "    domain = constraints.real\n",
        "    codomain = constraints.real\n",
        "    bijective = False\n",
        "    event_dim = 1\n",
        "    def __init__(self, dim):\n",
        "        super(ShuffleFlow, self).__init__(dim)\n",
        "        self.permute = torch.randperm(dim)\n",
        "        self.inverse = torch.argsort(self.permute)"
      ],
      "metadata": {
        "id": "kdt4oNuN0gb5"
      },
      "id": "kdt4oNuN0gb5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our different flow blocks\n",
        "block_real_nvp = [ AffineCouplingFlow, ReverseFlow, BatchNormFlow ]"
      ],
      "metadata": {
        "id": "kNrYYBvn0j4-"
      },
      "id": "kNrYYBvn0j4-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create normalizing flow\n",
        "flow_real_nvp = NormalizingFlow(dim=2, blocks=block_real_nvp, flow_length=4, density=distrib.MultivariateNormal(torch.zeros(2), torch.eye(2)))"
      ],
      "metadata": {
        "id": "E1FVnj1S4naU"
      },
      "id": "E1FVnj1S4naU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as distrib\n",
        "import torch.distributions.transforms as transform\n",
        "# Imports for plotting\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "matplotlib.rcParams['animation.ffmpeg_path'] = '/content/ffmpeg'\n",
        "from IPython.display import HTML\n",
        "# Define grids of points (for later plots)\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
        "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])"
      ],
      "metadata": {
        "id": "lVKS02bN3k6h"
      },
      "id": "lVKS02bN3k6h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_flow(flow, loss, optimizer, scheduler, target_density, epochs=10001, plot_it=1000):\n",
        "    ref_distrib = distrib.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
        "    ims = []\n",
        "    #fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 7))\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    # Main optimization loop\n",
        "    for it in range(epochs):\n",
        "        # Draw a sample batch from Normal\n",
        "        samples = ref_distrib.sample((512, ))\n",
        "        # Evaluate flow of transforms\n",
        "        zk, log_jacobians = flow(samples)\n",
        "        # Evaluate loss and backprop\n",
        "        #optimizer.zero_grad()\n",
        "        loss_v = loss(target_density, zk, log_jacobians)\n",
        "        loss_v.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if (it % plot_it == 0):\n",
        "            print('Loss (it. %i) : %f'%(it, loss_v.item()))\n",
        "            # Draw random samples\n",
        "            samples = ref_distrib.sample((int(1e5), ))\n",
        "            # Evaluate flow and plot\n",
        "            zk, _ = flow(samples)\n",
        "            zk = zk.detach().numpy()\n",
        "            im = plt.hexbin(zk[:,0], zk[:,1], cmap='rainbow', animated='True')\n",
        "            ims.append([im])\n",
        "    #ax1.hexbin(z[:,0], z[:,1], C=target_density(torch.Tensor(z)).numpy().squeeze(), cmap='rainbow')\n",
        "    #ax1.set_title('Target density', fontsize=15);\n",
        "    #ax2.hexbin(zk[:,0], zk[:,1], cmap='rainbow')\n",
        "    #ax2.set_title('Final approximation', fontsize=15)\n",
        "    anim = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "    HTML(anim.to_html5_video())\n",
        "    anim.save(\"check.mp4\")\n",
        "    #ax3.set_title('Optimization process', fontsize=15)"
      ],
      "metadata": {
        "id": "BE_8929P3fEt"
      },
      "id": "BE_8929P3fEt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create optimizer algorithm\n",
        "optimizer = optim.Adam(flow_real_nvp.parameters(), lr=1e-3)\n",
        "# Add learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.99995)\n",
        "# Launch the optimization\n",
        "train_flow(flow_real_nvp, loss, optimizer, scheduler, density_wave, epochs=150, plot_it=20)"
      ],
      "metadata": {
        "id": "r65lO3bj1hKz"
      },
      "id": "r65lO3bj1hKz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVdb0f9m4wR7"
      },
      "id": "JVdb0f9m4wR7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}