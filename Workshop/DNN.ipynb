{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d81e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn import preprocessing, neighbors, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10c291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('rechit_features_with_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95eae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9f17ef-c5d2-4a0d-abe9-e84efbdaff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target_energy'], axis=1)\n",
    "y = df['target_energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa24deb7-2fa1-44db-9aa5-2475de765221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Step 1: Split into temp (train+val) and test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Split temp into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b4a527-0219-4297-a1e3-a6e67ae7d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleDNN(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SimpleDNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 64)  # First hidden layer\n",
    "#         self.fc2 = nn.Linear(64, 64)         # Second hidden layer\n",
    "#         self.out = nn.Linear(64, 1)          # Output layer for regression\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))  # First layer with ReLU\n",
    "#         x = F.relu(self.fc2(x))  # Second layer with ReLU\n",
    "#         x = self.out(x)          # Output (no activation for regression)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f668342d-482f-43c7-8e6c-a8cd97861d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class SimpleDNN(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SimpleDNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 128)   # Was 64\n",
    "#         self.fc2 = nn.Linear(128, 128)         # Was 64\n",
    "#         self.fc3 = nn.Linear(128, 128)         # New third hidden layer\n",
    "#         self.out = nn.Linear(128, 1)           # Output layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))   # Layer 1\n",
    "#         x = F.relu(self.fc2(x))   # Layer 2\n",
    "#         x = F.relu(self.fc3(x))   # Layer 3 (new)\n",
    "#         x = self.out(x)           # Output\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1879ee-c1f9-425d-9765-3186a41a0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example input dimension\n",
    "# input_dim = X_train.shape[1]  # if X_train is a NumPy array\n",
    "\n",
    "# # Create model\n",
    "# model = SimpleDNN(input_dim=input_dim)\n",
    "# # model = ComplexDNN(input_dim)\n",
    "\n",
    "# # Define loss and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9907e9-d619-4a28-bab9-144c370d3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert DataFrame to tensor\n",
    "# X_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "# y_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)  # shape [N, 1]\n",
    "\n",
    "# # Wrap into Dataset and DataLoader\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a55f4464-dc33-4b19-9a2f-5c41c89f078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 100\n",
    "# model.train()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_X, batch_y in train_loader:\n",
    "#         # Forward pass\n",
    "#         outputs = model(batch_X)\n",
    "#         loss = criterion(outputs, batch_y)\n",
    "\n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a088ed65-ad3f-41fc-953b-22317a516428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# # Select device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Initialize model and move to device\n",
    "# input_dim = X_train.shape[1]\n",
    "# model = SimpleDNN(input_dim=input_dim).to(device)\n",
    "\n",
    "# # Loss and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# # Convert DataFrame to tensor and move to device\n",
    "# X_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "# y_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# # Dataset and DataLoader\n",
    "# train_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 100\n",
    "# model.train()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_X, batch_y in train_loader:\n",
    "#         # No need to move batch_X, batch_y to device again; already done\n",
    "#         outputs = model(batch_X)\n",
    "#         loss = criterion(outputs, batch_y)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a785fe6-19c2-4fd6-a320-5e86fff46c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] Train Loss: 3579.6655, Val Loss: 181.0463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40] Train Loss: 46.2595, Val Loss: 19.2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40] Train Loss: 16.9032, Val Loss: 16.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40] Train Loss: 15.0363, Val Loss: 14.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40] Train Loss: 13.1625, Val Loss: 12.5704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40] Train Loss: 11.7304, Val Loss: 11.5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define model\n",
    "# class SimpleDNN(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SimpleDNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 64)\n",
    "#         self.fc2 = nn.Linear(64, 64)\n",
    "#         self.out = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         return self.out(x)\n",
    "\n",
    "# class SimpleDNN(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(SimpleDNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 32)   # Was 64\n",
    "#         self.fc2 = nn.Linear(32, 64)         # Was 64\n",
    "#         self.fc3 = nn.Linear(64, 64)         # New third hidden layer\n",
    "#         self.out = nn.Linear(64, 1)           # Output layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))   # Layer 1\n",
    "#         x = F.relu(self.fc2(x))   # Layer 2\n",
    "#         x = F.relu(self.fc3(x))   # Layer 3 (new)\n",
    "#         x = self.out(x)           # Output\n",
    "#         return x\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class SimpleDNN(nn.Module):\n",
    "#     def __init__(self, input_dim, dropout_prob=0.2):\n",
    "#         super(SimpleDNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 64)\n",
    "#         self.fc2 = nn.Linear(64, 128)\n",
    "#         self.fc3 = nn.Linear(128, 128)\n",
    "#         self.fc4 = nn.Linear(128, 64)\n",
    "#         self.out = nn.Linear(64, 1)\n",
    "#         # self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         # x = self.dropout(x)           # Dropout after second hidden layer\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         # x = self.dropout(x)           # Dropout after third hidden layer\n",
    "#         x = F.relu(self.fc4(x))\n",
    "#         x = self.out(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class SimpleDNN(nn.Module):\n",
    "#     def __init__(self, input_dim, dropout_prob=0.2):\n",
    "#         super(SimpleDNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 64)\n",
    "#         self.bn1 = nn.BatchNorm1d(64)\n",
    "\n",
    "#         self.fc2 = nn.Linear(64, 128)\n",
    "#         self.bn2 = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.fc3 = nn.Linear(128, 128)\n",
    "#         self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.fc4 = nn.Linear(128, 64)\n",
    "#         self.bn4 = nn.BatchNorm1d(64)\n",
    "\n",
    "#         self.out = nn.Linear(64, 1)\n",
    "#         # self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.fc1(x)))\n",
    "#         x = F.relu(self.bn2(self.fc2(x)))\n",
    "#         # x = self.dropout(x)\n",
    "#         x = F.relu(self.bn3(self.fc3(x)))\n",
    "#         # x = self.dropout(x)\n",
    "#         x = F.relu(self.bn4(self.fc4(x)))\n",
    "#         x = self.out(x)\n",
    "#         return x\n",
    "\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_prob=0.2):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        # self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# class IdealDNN(nn.Module):\n",
    "#     def __init__(self, input_dim, dropout_prob=0.3):\n",
    "#         super(IdealDNN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 128)\n",
    "#         self.bn1 = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.fc2 = nn.Linear(128, 256)\n",
    "#         self.bn2 = nn.BatchNorm1d(256)\n",
    "\n",
    "#         self.fc3 = nn.Linear(256, 256)\n",
    "#         self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.bn4 = nn.BatchNorm1d(128)\n",
    "\n",
    "#         self.out = nn.Linear(128, 1)\n",
    "\n",
    "#         self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn1(self.fc1(x)))\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         x = F.relu(self.bn2(self.fc2(x)))\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         x = F.relu(self.bn3(self.fc3(x)))\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         x = F.relu(self.bn4(self.fc4(x)))\n",
    "#         x = self.dropout(x)\n",
    "\n",
    "#         x = self.out(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "# X_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "# y_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "# val_loader = DataLoader(val_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "# Convert all to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Wrap in datasets\n",
    "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_ds   = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_ds  = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=10000, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=10000, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=10000, shuffle=False)\n",
    "\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = SimpleDNN(X_train.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Lists to store loss\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1:03d}\", leave=False)\n",
    "\n",
    "    for batch_X, batch_y in pbar:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item() * batch_X.size(0)\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_y in val_loader:\n",
    "            val_X, val_y = val_X.to(device), val_y.to(device)\n",
    "            val_outputs = model(val_X)\n",
    "            val_loss = criterion(val_outputs, val_y)\n",
    "            running_val_loss += val_loss.item() * val_X.size(0)\n",
    "\n",
    "    avg_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d9e39-08a9-4909-9e34-72d98c7623ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df470db-67d4-43ff-9ff0-3de9f5b2e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "#     y_pred = model(X_test_tensor).numpy()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)  # move to GPU\n",
    "    outputs = model(X_test_tensor)\n",
    "    y_pred = outputs.cpu().numpy()  # move back to CPU before numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a3dd3-7abb-4dbe-b4e2-7e0d7d362401",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752ca17-5742-477d-abf1-cea797455cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y_pred is on CPU and converted to NumPy\n",
    "y_pred_np = y_pred.cpu().numpy() if torch.is_tensor(y_pred) else y_pred\n",
    "\n",
    "# y_test is likely still a pandas Series or NumPy array\n",
    "y_test_np = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "\n",
    "# Avoid division by zero\n",
    "epsilon = 1e-8\n",
    "response = y_test_np.flatten() / (y_pred_np.flatten() + epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8246779-65dd-4764-a9e7-22295d3ef9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_np/y_pred_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7637f-b3ab-48b6-833d-3fb0562943a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(response, bins=1000, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Response (y_test / y_pred)')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(0.9, 1.1)\n",
    "plt.title('Response Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1be23-9643-4690-97f0-5ef250453e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-8\n",
    "response = y_test_np.flatten() / (y_pred_np.flatten() + epsilon)\n",
    "\n",
    "# Optionally: restrict to reasonable range (truncate manually)\n",
    "response = response[(response > 0.9) & (response < 1.1)]  # or whatever makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d5515-51f7-4192-af98-585037811adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_gaussian(x, mu, sigma, a, b):\n",
    "    # a and b are bounds in standard normal units\n",
    "    a_scaled = (a - mu) / sigma\n",
    "    b_scaled = (b - mu) / sigma\n",
    "    return truncnorm.pdf(x, a_scaled, b_scaled, loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43c16d-5306-42ea-af06-77ae81b01983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "counts, bin_edges = np.histogram(response, bins=1000, density=True)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# Fit\n",
    "popt, _ = curve_fit(\n",
    "    lambda x, mu, sigma: truncated_gaussian(x, mu, sigma, a=0.9, b=1.1),\n",
    "    bin_centers, counts, p0=[1.0, 0.1]\n",
    ")\n",
    "mu_fit, sigma_fit = popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4fbcc-d58d-40d7-ade7-2e3842e2f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = np.linspace(0.9, 1.1, 100)\n",
    "pdf_vals = truncated_gaussian(x_vals, mu_fit, sigma_fit, a=0.5, b=1.5)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(response, bins=100, density=True, color='skyblue', alpha=0.6, label='Response Histogram')\n",
    "plt.plot(x_vals, pdf_vals, 'r-', label=f'Trunc Gauss Fit\\nμ={mu_fit:.3f}, σ={sigma_fit:.3f}')\n",
    "plt.xlabel('Response (y_test / y_pred)')\n",
    "plt.xlim(0.9, 1.1)\n",
    "plt.ylim(0, 30)\n",
    "plt.ylabel('Density')\n",
    "plt.title('Fitted Truncated Gaussian to Response')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e95bac-4659-4fb5-b8fa-72892d22d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Truncated Gaussian PDF\n",
    "def truncated_gaussian(x, mu, sigma, a=0.9, b=1.1):\n",
    "    a_, b_ = (a - mu) / sigma, (b - mu) / sigma\n",
    "    return truncnorm.pdf(x, a_, b_, loc=mu, scale=sigma)\n",
    "\n",
    "# Fit wrapper\n",
    "def fit_func(x, mu, sigma):\n",
    "    return truncated_gaussian(x, mu, sigma)\n",
    "\n",
    "# Step 1: Prepare data\n",
    "y_test_np = y_test.values if hasattr(y_test, 'values') else y_test\n",
    "y_pred_np = y_pred\n",
    "y_test_np = y_test_np.flatten()\n",
    "y_pred_np = y_pred_np.flatten()\n",
    "\n",
    "# Step 2: Binning based on y_test\n",
    "# bin_edges = np.arange(0, y_test_np.max()+10 , 10)\n",
    "bin_edges = np.arange(5, y_test_np.max() + 10, 10)\n",
    "\n",
    "bin_indices = np.digitize(y_test_np, bin_edges)\n",
    "\n",
    "# Step 3: Containers\n",
    "response_bins = []\n",
    "bin_centers = []\n",
    "mu_vals, sigma_vals, mu_errs, sigma_errs = [], [], [], []\n",
    "epsilon = 1e-8\n",
    "\n",
    "# Step 4: Fit truncated Gaussian per bin\n",
    "for i in range(1, len(bin_edges)):\n",
    "    indices = np.where(bin_indices == i)[0]\n",
    "    if len(indices) < 10:\n",
    "        continue\n",
    "\n",
    "    y_test_bin = y_test_np[indices]\n",
    "    y_pred_bin = y_pred_np[indices]\n",
    "    response = y_test_bin / (y_pred_bin + epsilon)\n",
    "    response_bins.append(response)\n",
    "    center = (bin_edges[i - 1] + bin_edges[i]) / 2\n",
    "    bin_centers.append(center)\n",
    "\n",
    "    hist_vals, bin_edges_hist = np.histogram(response, bins=50, range=(0.9, 1.1), density=True)\n",
    "    bin_centers_hist = 0.5 * (bin_edges_hist[1:] + bin_edges_hist[:-1])\n",
    "    mu_guess = np.mean(response)\n",
    "    sigma_guess = np.std(response)\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(fit_func, bin_centers_hist, hist_vals, p0=[mu_guess, sigma_guess])\n",
    "        mu_fit, sigma_fit = popt\n",
    "        mu_vals.append(mu_fit)\n",
    "        sigma_vals.append(sigma_fit)\n",
    "        mu_errs.append(np.sqrt(pcov[0, 0]))\n",
    "        sigma_errs.append(np.sqrt(pcov[1, 1]))\n",
    "    except Exception as e:\n",
    "        print(f\"Fit failed for bin {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Step 5: Plot all fits with tight layout\n",
    "n_plots = len(response_bins)\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(n_plots / n_cols))\n",
    "\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axs = axs.flatten() if n_plots > 1 else [axs]\n",
    "\n",
    "for plot_idx in range(n_plots):\n",
    "    ax = axs[plot_idx]\n",
    "    response = response_bins[plot_idx]\n",
    "    center = bin_centers[plot_idx]\n",
    "    mu_fit = mu_vals[plot_idx]\n",
    "    sigma_fit = sigma_vals[plot_idx]\n",
    "\n",
    "    hist_vals, bin_edges_hist = np.histogram(response, bins=50, range=(0.9, 1.1), density=True)\n",
    "    bin_centers_hist = 0.5 * (bin_edges_hist[1:] + bin_edges_hist[:-1])\n",
    "    x_fit = np.linspace(0.9, 1.1, 200)\n",
    "\n",
    "    ax.hist(response, bins=50, range=(0.9, 1.1), density=True, alpha=0.6, color='skyblue', label='Response')\n",
    "    ax.plot(x_fit, truncated_gaussian(x_fit, mu_fit, sigma_fit), 'r-', lw=2, label='Trunc. Gaussian Fit')\n",
    "    ax.set_title(f'Bin Center: {center:.0f} GeV')\n",
    "    ax.set_xlabel(\"Response (y_test / y_pred)\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.text(0.91, np.max(hist_vals) * 0.8, f\"$\\\\mu$ = {mu_fit:.4f}\\n$\\\\sigma$ = {sigma_fit:.4f}\", fontsize=10)\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(n_plots, len(axs)):\n",
    "    axs[j].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Summary plots\n",
    "\n",
    "# Convert lists to arrays\n",
    "mu_vals = np.array(mu_vals)\n",
    "sigma_vals = np.array(sigma_vals)\n",
    "mu_errs = np.array(mu_errs)\n",
    "sigma_errs = np.array(sigma_errs)\n",
    "bin_centers = np.array(bin_centers)\n",
    "\n",
    "# Calculate σ/μ and its uncertainty\n",
    "sigma_over_mu = sigma_vals / mu_vals\n",
    "sigma_over_mu_err = sigma_over_mu * np.sqrt((sigma_errs / sigma_vals)**2 + (mu_errs / mu_vals)**2)\n",
    "\n",
    "# Plot σ/μ\n",
    "plt.errorbar(bin_centers, sigma_over_mu, yerr=sigma_over_mu_err, fmt='o-', capsize=5)\n",
    "plt.xlabel(\"True Energy [GeV]\")\n",
    "plt.ylabel(\"σ / μ\")\n",
    "plt.title(\"Relative Resolution vs True Energy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot μ\n",
    "plt.errorbar(bin_centers, mu_vals, yerr=mu_errs, fmt='o-', capsize=5)\n",
    "plt.xlabel(\"True Energy [GeV]\")\n",
    "plt.ylabel(\"Mean Response (μ)\")\n",
    "plt.title(\"Mean Response vs True Energy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f4448-2dbc-4256-a8ce-c5873ee958e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fit function: sqrt( (S/sqrt(E))^2 + C^2 )\n",
    "def resolution_model(E, S, C):\n",
    "    return np.sqrt((S / np.sqrt(E))**2 + C**2)\n",
    "\n",
    "# Initial guess: S = 0.3, C = 0.01\n",
    "popt, pcov = curve_fit(resolution_model, bin_centers, sigma_over_mu,\n",
    "                       sigma=sigma_over_mu_err, p0=[0.3, 0.01], absolute_sigma=True)\n",
    "\n",
    "S_fit, C_fit = popt\n",
    "S_err, C_err = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# Print results\n",
    "print(f\"Stochastic term (S): {S_fit:.4f} ± {S_err:.4f}\")\n",
    "print(f\"Constant term (C):   {C_fit:.4f} ± {C_err:.4f}\")\n",
    "\n",
    "# Plot the fit over the data\n",
    "E_plot = np.linspace(min(bin_centers), max(bin_centers), 300)\n",
    "fit_curve = resolution_model(E_plot, S_fit, C_fit)\n",
    "\n",
    "plt.errorbar(bin_centers, sigma_over_mu, yerr=sigma_over_mu_err, fmt='o', capsize=5, label='Data')\n",
    "plt.plot(E_plot, fit_curve, 'r--', label=f'Fit: $\\\\sqrt{{(S/\\\\sqrt{{E}})^2 + C^2}}$\\nS = {S_fit:.4f} ± {S_err:.4f}\\nC = {C_fit:.4f} ± {C_err:.4f}')\n",
    "plt.xlabel(\"True Energy [GeV]\")\n",
    "plt.ylabel(\"σ / μ\")\n",
    "plt.title(\"Fit of σ/μ with Stochastic and Constant Term\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
