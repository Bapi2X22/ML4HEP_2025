{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c274dbc-c9e9-4c77-a9a3-05bea7b8ef53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 11 16:52:32 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:07.0 Off |                    0 |\n",
      "| N/A   50C    P8             17W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653354f6-eb20-433a-8aee-9bddb90f8b2e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Not compiled with CUDA support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_403/374987972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_107_cuda/x86_64-el9-gcc11-opt/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_107_cuda/x86_64-el9-gcc11-opt/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_403/374987972.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0medge_conv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_conv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_conv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_conv3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_107_cuda/x86_64-el9-gcc11-opt/lib/python3.11/site-packages/torch_geometric/nn/pool/__init__.py\u001b[0m in \u001b[0;36mknn_graph\u001b[0;34m(x, k, batch, loop, flow, cosine, num_workers, batch_size)\u001b[0m\n\u001b[1;32m    171\u001b[0m         return torch_cluster.knn_graph(x, k, batch, loop, flow, cosine,\n\u001b[1;32m    172\u001b[0m                                        num_workers)\n\u001b[0;32m--> 173\u001b[0;31m     return torch_cluster.knn_graph(x, k, batch, loop, flow, cosine,\n\u001b[0m\u001b[1;32m    174\u001b[0m                                    num_workers, batch_size)\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_107_cuda/x86_64-el9-gcc11-opt/lib/python3.11/site-packages/torch_cluster/knn.py\u001b[0m in \u001b[0;36mknn_graph\u001b[0;34m(x, k, batch, loop, flow, cosine, num_workers, batch_size)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'source_to_target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_to_source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     edge_index = knn(x, x, k if loop else k + 1, batch, batch, cosine,\n\u001b[0m\u001b[1;32m    133\u001b[0m                      num_workers, batch_size)\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_107_cuda/x86_64-el9-gcc11-opt/lib/python3.11/site-packages/torch_cluster/knn.py\u001b[0m in \u001b[0;36mknn\u001b[0;34m(x, y, k, batch_x, batch_y, cosine, num_workers, batch_size)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mptr_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucketize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return torch.ops.torch_cluster.knn(x, y, ptr_x, ptr_y, k, cosine,\n\u001b[0m\u001b[1;32m     82\u001b[0m                                        num_workers)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_107_cuda/x86_64-el9-gcc11-opt/lib/python3.11/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Not compiled with CUDA support"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import knn_graph, EdgeConv, global_mean_pool\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import h5py\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# Model Components\n",
    "# ------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class RechitGNN(nn.Module):\n",
    "    def __init__(self, k=16):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.edge_conv1 = EdgeConv(MLP(2 * 128, 128))\n",
    "        self.edge_conv2 = EdgeConv(MLP(2 * 128, 128))\n",
    "        self.edge_conv3 = EdgeConv(MLP(2 * 128, 128))\n",
    "\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data: Batch):\n",
    "        x, pos, batch = data.x, data.pos, data.batch\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        for edge_conv in [self.edge_conv1, self.edge_conv2, self.edge_conv3]:\n",
    "            edge_index = knn_graph(x, k=self.k, batch=batch)\n",
    "            x = edge_conv(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        out = self.output_mlp(x)\n",
    "        return out.view(-1)\n",
    "\n",
    "# ------------------------------\n",
    "# Dataset Class\n",
    "# ------------------------------\n",
    "class RechitEventDataset(Dataset):\n",
    "    def __init__(self, events, target_energy):\n",
    "        assert len(events) == len(target_energy)\n",
    "        self.events = events\n",
    "        self.targets = target_energy\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.events)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.events[idx]\n",
    "        y = self.targets[idx]\n",
    "\n",
    "        x = torch.tensor(e['x'], dtype=torch.float32)\n",
    "        y_ = torch.tensor(e['y'], dtype=torch.float32)\n",
    "        z = torch.tensor(e['z'], dtype=torch.float32)\n",
    "        E = torch.tensor(e['E'], dtype=torch.float32)\n",
    "\n",
    "        features = torch.stack([x, y_, z, E], dim=-1)\n",
    "        pos = features[:, :3]\n",
    "        y_target = torch.tensor([y], dtype=torch.float32)\n",
    "\n",
    "        return Data(x=features, pos=pos, y=y_target)\n",
    "\n",
    "# ------------------------------\n",
    "# Load Data\n",
    "# ------------------------------\n",
    "with open('events.pkl', 'rb') as f:\n",
    "    events = pk.load(f)\n",
    "\n",
    "with h5py.File(\"hgcal_electron_data_0001.h5\", \"r\") as f:\n",
    "    target_energy = f[\"target\"][:]\n",
    "\n",
    "# ------------------------------\n",
    "# Prepare Dataset and Split\n",
    "# ------------------------------\n",
    "dataset = RechitEventDataset(events, target_energy)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=60, shuffle=False)\n",
    "\n",
    "# ------------------------------\n",
    "# Train Model with Progress Bar\n",
    "# ------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = RechitGNN(k=16).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch:03d}\", leave=False)\n",
    "\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = loss_fn(out, batch.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "        avg_loss = total_loss / ((pbar.n + 1) * batch.num_graphs)\n",
    "        pbar.set_postfix(loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} completed, Avg Loss: {total_loss / len(train_dataset):.4f}\")\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), \"rechit_regression_model.pt\")\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluate on Test Set\n",
    "# ------------------------------\n",
    "model.eval()\n",
    "predictions = []\n",
    "truths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch)\n",
    "        predictions.extend(out.cpu().numpy())\n",
    "        truths.extend(batch.y.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "truths = np.array(truths)\n",
    "\n",
    "# Save to files\n",
    "np.save(\"predicted_energy_test.npy\", predictions)\n",
    "np.save(\"true_energy_test.npy\", truths)\n",
    "print(\"Predictions saved as .npy files.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Plot Predictions vs Truth\n",
    "# ------------------------------\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(truths, predictions, alpha=0.5, edgecolors='k')\n",
    "# plt.xlabel(\"True Energy\")\n",
    "# plt.ylabel(\"Predicted Energy\")\n",
    "# plt.title(\"GNN Energy Regression\")\n",
    "# plt.plot([truths.min(), truths.max()], [truths.min(), truths.max()], 'r--')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"truth_vs_prediction.png\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
